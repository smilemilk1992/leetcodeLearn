实战：
# redis-https://www.cnblogs.com/2020-zhy-jzoj/p/13164739.html
1、有没有遇到什么坑

    业务端一般认为redis出现问题，就是redis云有问题，人的“正常”思维：看别人错误容易，发现自己难，扯多了, 出现这个有很多原因：
       (1). 网络原因：比如是否存在跨机房、网络割接等等。
       (2). 慢查询，因为redis是单线程，如果有慢查询的话，会阻塞住之后的操作。 
       (3). value值过大？比如value几十兆，当然这种情况比较少，其实也可以看做是慢查询的一种
       (4). aof重写/rdb fork发生？瞬间会堵一下Redis服务器。
2、redis主从同步过程

    1.从服务发送一个sync同步命令给主服务要求全量同步。
    2.主服务接收到从服务的sync同步命令时，会fork一个子进程后台执行bgsave命令（非阻塞）快照保存，生成RDB文件，并将RDB文件发送给从服务。
    3.从服务再将接收到的RDB文件载入自己的redis内存。
    4.待从服务将RDB载入完成后，主服务再将缓冲区所有写命令发送给从服务。
    5.从服务在将主服务所有的写命令载入内存从而实现数据的完整同步。
    6.从服务下次在需要同步数据时只需要发送自己的offset位置（相当于MySQL binlog的位置）即可，只同步新增加的数据，再不需要全量同步。
    主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。redis 策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。

3、redis哨兵机制-https://www.jianshu.com/p/3677afe376ee

    哨兵(Sentinel)主要是为了解决在主从复制架构中出现宕机的情况,是建立在主从模式的基础上面的
    Redis-Sentinel是Redis官方推荐的高可用（HA）方案，当用Reids 做master-slave高可用方案时，假如master宕机了，redis本身（包括它的很多客服端）都没有实现自动的主备切换，而Redis-Sentinel本身也是一个独立运行的进程，它能监控多个master-slave集群，发现master宕机后能自动切换。



4、redis原理，跳表的时间复杂度

    Redis 是一款基于 ANSI C 语言编写的，BSD 许可的，日志型 key-value 存储组件，它的所有数据结构都存在内存中，可以用作缓存、数据库和消息中间件。
    redis是nosql(也是个巨大的map) 单线程，但是可处理1秒10w的并发（数据都在内存中）
    跳表其实是多条链表组成的链表结构，其特点在于查询时能够跳跃式查询。其复杂度取决于链表的跳跃区间的离散程度。


5、redis集群模式

    * 主从模式（主从模式的弊端就是不具备高可用性，当master挂掉以后，Redis将不能再对外提供写入操作）
        * 主数据库可以进行读写操作，当读写操作导致数据变化时会自动将数据同步给从数据库
        * 从数据库一般都是只读的，并且接收主数据库同步过来的数据
        * 一个master可以拥有多个slave，但是一个slave只能对应一个master
        * slave挂了不影响其他slave的读和master的读和写，重新启动后会将数据从master同步过来
        * master挂了以后，不影响slave的读，但redis不再提供写服务，master重启后redis将重新对外提供写服务
        * master挂了以后，不会在slave节点中重新选一个master
        * 可以实现读写分离，数据备份。但是并不是「高可用」的
    
    * Sentinel模式
        * sentinel模式是建立在主从模式的基础上，如果只有一个Redis节点，sentinel就没有任何意义
        * 当master挂了以后，sentinel会在slave中选择一个做为master，并修改它们的配置文件，其他slave的配置文件也会被修改，比如slaveof属性会指向新的master
        * 当master重新启动后，它将不再是master而是做为slave接收新的master的同步数据
        * sentinel因为也是一个进程有挂掉的可能，所以sentinel也会启动多个形成一个sentinel集群
        * 多sentinel配置的时候，sentinel之间也会自动监控
        * 当主从模式配置密码时，sentinel也会同步将配置信息修改到配置文件中，不需要担心
        * 一个sentinel或sentinel集群可以管理多个主从Redis，多个sentinel也可以监控同一个redis
        * sentinel最好不要和Redis部署在同一台机器，不然Redis的服务器挂了以后，sentinel也挂了
        * Redis哨兵模式实现了高可用，读写分离，但是其主节点仍然只有一个，即写入操作都是在主节点中，这也成为了性能的瓶颈。
    * 集群模式
        * Redis 集群没有使用一致性 hash,而是引入了哈希槽的概念，Redis 集群有 16384 个哈希槽，每个 key 通过 CRC16 校验后对 16384 取模来决定放置哪个槽， 集群的每个节点负责一部分 hash 槽。
        * 集群至少需要3主3从
        * 不仅提供了高可用的手段，同时数据是分片保存在各个节点中的，可以支持高并发的写入与读取。当然实现也是其中最复杂的。
        


6、redis雪崩和穿透怎么解决-https://zhuanlan.zhihu.com/p/58331707  https://www.cnblogs.com/liluxiang/p/10320491.html

    血崩：
    1、redis集群大面积故障
    2、缓存失效，但依然大量请求访问缓存服务redis
    3、redis大量失效后，大量请求转向到mysql数据库
    4、mysql的调用量暴增，很快就扛不住了，甚至直接宕机
    5、由于大量的应用服务依赖mysql和redis的服务，这个时候很快会演变成各服务器集群的雪崩，最后网站彻底崩溃。
    
    如何解决：
    1、缓存高可用
    2、缓存降级
    3、Redis备份和快速预热
    4、提前演练
    
    穿透：
    缓存穿透是指查询一个一不存在的数据。例如：从缓存redis没有命中，需要从mysql数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。
    
    解决：
    如果查询数据库也为空，直接设置一个默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库。设置一个过期时间或者当有值的时候将缓存中的值替换掉即可。

    可以给key设置一些格式规则，然后查询之前先过滤掉不符合规则的Key。
    
7、热点缓存问题-https://www.cnblogs.com/xuwc/p/14013060.html

    热key问题，指的就是缓存集群中的某个key在瞬间被数万甚至十万的并发请求打爆。大value问题，指的是某个key对应的value可能有gb级别的大小，导致查询value的时候会引发网络相关的故障问题。这里说一下热key问题。
    所谓热key问题就是，突然有几十万的请求去访问redis上的某个特定key。那么，这样会造成流量过于集中，达到物理网卡上限，从而导致这台redis的服务器宕机。
    那接下来这个key的请求，就会直接怼到你的数据库上，导致你的服务不可用。

    发现热key:
    1、凭借业务经验，进行预估哪些是热key
    2、在客户端进行收集
    3、在Proxy层做收集
    4、用redis自带命令
    
    如何解决：
    1、利用二级缓存
    比如利用ehcache，或者一个HashMap都可以。在你发现热key以后，把热key加载到系统的JVM中。
    针对这种热key请求，会直接从jvm中取，而不会走到redis层。
    假设此时有十万个针对同一个key的请求过来,如果没有本地缓存，这十万个请求就直接怼到同一台redis上了。
    现在假设，你的应用层有50台机器，OK，你也有jvm缓存了。这十万个请求平均分散开来，每个机器有2000个请求，会从JVM中取到value值，然后返回数据。避免了十万个请求怼到同一台redis上的情形。
    2、备份热key
    这个方案也很简单。不要让key走到同一台redis上不就行了。我们把这个key，在多个redis上都存一份不就好了。接下来，有热key请求进来的时候，我们就在有备份的redis上随机选取一台，进行访问取值，返回数据。
    3、监控热key
    4、通知系统做处理

# hashmap
1、HashMap内部怎么实现的

    HashMap的主干是一个Entry数组。Entry是HashMap的基本组成单元，每一个Entry包含一个key-value键值对。
    简单来说，HashMap由数组+链表+红黑树组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的，如果定位到的数组位置不含链表（当前entry的next指向null）,那么对于查找，添加等操作很快，仅需一次寻址即可；如果定位到的数组包含链表，对于添加操作，其时间复杂度为O(n)，首先遍历链表，存在即覆盖，否则新增；对于查找操作来讲，仍需遍历链表，然后通过key对象的equals方法逐一比对查找。所以，性能考虑，HashMap中的链表出现越少，性能才会越好。
    
2、Hashmap扩容做了什么操作，为什么要扩容成两倍

    扩容的时候1.7需要对原数组中的元素进行重新hash定位在新数组的位置，1.8采用更简单的判断逻辑，位置不变或索引+旧容量大小；
    
    HashMap的初始容量是2的n次幂，扩容也是2倍的形式进行扩容，是因为容量是2的n次幂，可以使得添加的元素均匀分布在HashMap中的数组上，减少hash碰撞，避免形成链表的结构，使得查询效率降低！
    
3、HashMap的put操作过程
 思路如下：
 
    1、如果HashMap没有被初始化过，则初始化
    2、对key求Hash值，然后在计算下标
    3、如果没有碰撞则直接放入桶中
    4、如果碰撞了，以链表的方式链接到后面（尾插法）
    5、如果链表长度超过阈值8，就把链表转为红黑树
    6、如果链表长度低于6，就把红黑树转回链表
    7、如果节点已经存在就替换旧值
    8、如果桶满了（16*加载因子0.75）， 就需要resize（扩容两倍后重排-位置不变或索引+旧容量大小）

4、hashmap线程不安全的体现

    1.在jdk1.7中，在多线程环境下，扩容时会造成环形链或数据丢失。
    2.在jdk1.8中，在多线程环境下，会发生数据覆盖的情况。

#多线程
1、线程池拒绝策略

    1、AbortPolicy-直接抛出拒绝异常（继承自RuntimeException），会中断调用者的处理过程，所以除非有明确需求，一般不推荐
    2、CallerRunsPolicy-在调用者线程中（也就是说谁把 r 这个任务甩来的），运行当前被丢弃的任务。只会用调用者所在线程来运行任务，也就是说任务不会进入线程池。如果线程池已经被关闭，则直接丢弃该任务
    3、DiscardOledestPolicy-丢弃队列中最老的，然后再次尝试提交新任务。
    4、DiscardPolicy-默默丢弃无法加载的任务，不抛出异常。
    
2、volatile的原理
    
    volatile可见性：对一个volatile的读，总可以看到对这个变量最终的写；
    volatile原子性：volatile对单个读/写具有原子性（32位Long、Double），但是复合操作除外，例如：i++；
    jvm底层采用“内存屏障”来实现volatile语义。
    volatile的内存语义及实现：
        在JMM中，线程之间的通信采用共享内存来实现的。
    volatile内存语义是：

        当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值立即刷新到主内存中；
        当读一个volatile变量时，JMM会把该线程对应的本地内存设置为无效，直接从主内存中读取共享变量。
    
    volatile的底层实现是通过插入内存屏障，但是对于编译器来说，发现一个最优布置来最小化插入内存屏障的总数几乎是不可能的，所以，JMM采用保守策略。如下：
    
        在每一个volatile写操作前面插入一个StoreStore屏障
        在每一个volatile写操作后面插入一个StoreLoad屏障
        在每一个volatile读操作后面插入一个LoadLoad屏障
        在每一个volatile读操作后面插入一个LoadStore屏障
    StoreStore屏障可以保证在volatile写之前，其前面的所有普通写操作都已经刷新到主内存中；
    StoreLoad屏障的作用是避免volatile写与后面可能有的volatile读/写操作重排序
    LoadLoad屏障用来禁止处理器把上面的volatile读与下面的普通读重排序
    LoadStore屏障用来禁止处理器把上面的volatile读与下面的普通写重排序
    
    java中volatile关键字提供了一个功能，那就是被其修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在每次使用之前都从主内存刷新。因此，可以使用volatile来保证多线程操作时变量的可见性。
    
    在java中，可以使用synchronized和volatile来保证多线程之间操作的有序性。实现方式有所区别：
    
    1、volatile关键字会禁止指令重排；
    2、synchronized关键字保证同一时刻只允许一条线程操作。 synchronized是万能，他可以同时满足三种特性，这其实也是很多人滥用synchronized的原因。
        
    
3、	线程安全的场景和如何保证

    一般来说如果一个类有自己的可变状态，如成员变量，类变量，并且这些会在执行过程中改变它的值，那么就要考虑线程安全。
    
    如何保证：
    不在线程之间共享状态变量
    将状态变量修改成不可变的变量
    在访问状态变量时使用同步 
    加锁
        

#spring-https://zhuanlan.zhihu.com/p/266901018

```text
依旧以上面A、B类使用属性field注入循环依赖的例子为例，对整个流程做文字步骤总结如下：
使用context.getBean(A.class)，旨在获取容器内的单例A(若A不存在，就会走A这个Bean的创建流程)，显然初次获取A是不存在的，因此走A的创建之路~
实例化A（注意此处仅仅是实例化），并将它放进缓存（此时A已经实例化完成，已经可以被引用了）
初始化A：@Autowired依赖注入B（此时需要去容器内获取B）
为了完成依赖注入B，会通过getBean(B)去容器内找B。但此时B在容器内不存在，就走向B的创建之路~
实例化B，并将其放入缓存。（此时B也能够被引用了）
初始化B，@Autowired依赖注入A（此时需要去容器内获取A）
此处重要：初始化B时会调用getBean(A)去容器内找到A，上面我们已经说过了此时候因为A已经实例化完成了并且放进了缓存里，所以这个时候去看缓存里是已经存在A的引用了的，所以getBean(A)能够正常返回
B初始化成功（此时已经注入A成功了，已成功持有A的引用了），return（注意此处return相当于是返回最上面的getBean(B)这句代码，回到了初始化A的流程中~）。
因为B实例已经成功返回了，因此最终A也初始化成功
到此，B持有的已经是初始化完成的A，A持有的也是初始化完成的B，完美~
```
1、springboot 如何解决循环依赖？

    多个实例之间的相互依赖关系构成一个环形，就是循环依赖
    1、重新设计
        重新设计结构，消除循环依赖。
    2、使用注解@Lazy
        一种最简单的消除循环依赖的方式是通过延迟加载。在注入依赖时，先注入代理对象，当首次使用时再创建对象完成注入。
    3、使用Setter/Field注入
        Spring文档建议的一种方式是使用setter注入。当依赖最终被使用时才进行注入

2、循环依赖会出现什么问题？

    1、循环依赖会产生多米诺骨牌效应
        难以为代码编写测试，因为易变导致写的测试也不稳定
        难以重构，因为互相依赖，你改动一个自然会影响其他依赖对象
        难以维护，你根本不敢想象你的改动会造成什么样的后果
    2、循环依赖会导致内存溢出
    
3、spring循环依赖为什么用三级缓存-https://www.cnblogs.com/semi-sub/p/13548479.html

测试证明，二级缓存也是可以解决循环依赖的。为什么 Spring 不选择二级缓存，而要额外多添加一层缓存呢？

如果 Spring 选择二级缓存来解决循环依赖的话，那么就意味着所有 Bean 都需要在实例化完成之后就立马为其创建代理，
而 Spring 的设计原则是在 Bean 初始化完成之后才为其创建代理。所以，Spring 选择了三级缓存。
但是因为循环依赖的出现，导致了 Spring 不得不提前去创建代理，因为如果不提前创建代理对象，那么注入的就是原始对象，这样就会产生错误。

我们可以知道 Spring 需要三级缓存的目的是为了在没有循环依赖的情况下，延迟代理对象的创建，使 Bean 的创建符合 Spring 的设计原则。

Spring 解决循环依赖的核心就是提前暴露对象，而提前暴露的对象就是放置于第二级缓存中

| 名称	| 描述 |
| singletonObjects |	一级缓存，存放完整的 Bean。
| earlySingletonObjects |	二级缓存，存放提前暴露的Bean，Bean 是不完整的，未完成属性注入和执行 init 方法。|
| singletonFactories | 三级缓存，存放的是 Bean 工厂，主要是生产 Bean，存放到二级缓存中。 |

    Spring 是如何通过上面介绍的三级缓存来解决循环依赖的呢？这里只用 A，B 形成的循环依赖来举例：
    实例化 A，此时 A 还未完成属性填充和初始化方法（@PostConstruct）的执行，A 只是一个半成品。
    为 A 创建一个 Bean 工厂，并放入到 singletonFactories 中。
    发现 A 需要注入 B 对象，但是一级、二级、三级缓存均为发现对象 B。
    实例化 B，此时 B 还未完成属性填充和初始化方法（@PostConstruct）的执行，B 只是一个半成品。
    为 B 创建一个 Bean 工厂，并放入到 singletonFactories 中。
    发现 B 需要注入 A 对象，此时在一级、二级未发现对象 A，但是在三级缓存中发现了对象 A，从三级缓存中得到对象 A，并将对象 A 放入二级缓存中，同时删除三级缓存中的对象 A。（注意，此时的 A 还是一个半成品，并没有完成属性填充和执行初始化方法）
    将对象 A 注入到对象 B 中。
    对象 B 完成属性填充，执行初始化方法，并放入到一级缓存中，同时删除二级缓存中的对象 B。（此时对象 B 已经是一个成品）
    对象 A 得到对象 B，将对象 B 注入到对象 A 中。（对象 A 得到的是一个完整的对象 B）
    对象 A 完成属性填充，执行初始化方法，并放入到一级缓存中，同时删除二级缓存中的对象 A。
    
4、spring的bean是怎么管理的

    在Spring框架中，一旦把一个bean纳入到Spring IoC容器之中，这个bean的生命周期就会交由容器进行管理，一般担当管理者角色的是BeanFactory或ApplicationContext
    bean对象的生命周期
    1.单例对象（singleton时）
    (1)创建：容器创建时，对象创建。（加载完beans配置文件，对象也就创建了）
    (2)生存：只要容器还在，对象也一直存在。
    (3)消亡：容器销毁，对象消亡。
    总结：单例对象，与容器共存亡。
    
    2.多例对象（singleton时）
    (1)创建：当我们使用对象时，spring框架为我们创建。
    (2)生存：对象只要是在使用过程中就一直存在。
    (3)消亡：对象长时间不用，且没有别的对象引用时，由Java回收机制（GC）回收。
    总结：多例对象，与正常new出来的Java对象的生命周期一样。

5、applicationContext和beanFactory的区别

    ApplicationContext是继承了 BeanFactory 接口 所以 ApplicationContext 包含 BeanFactory 的所有功能以及更多功能
    BeanFactory：bean工厂接口；负责创建bean实例；容器里面保存的所有单例bean其实是一个map；Spring最底层的接口
    ApplicationContext：是容器接口；更多负责容器功能的实现；（可以基于BeanFactory创建好的对象之上完成强大的容器）
    容器可以从map中获取这个bean，并且可以进行aop、di等操作
    BeanFactory是最底层的接口，ApplicationContext留给程序员使用的ioc容器接口；ApplicationContext是BeanFactory的子接口
    ----------------------------------------
    BeanFactory 可以理解为含有bean集合的工厂类。BeanFactory 包含了种bean的定义，以便在接收到客户端请求时将对应的bean实例化。
    BeanFactory还能在实例化对象的时生成协作类之间的关系。此举将bean自身与bean客户端的配置中解放出来。BeanFactory还包含了bean生命周期的控制，调用客户端的初始化方法（initialization methods）和销毁方法（destruction methods）。
    从表面上看，ApplicationContext如同BeanFactory 一样具有bean定义、bean关联关系的设置，根据请求分发bean的功能。但ApplicationContext在此基础上还提供了其他的功能。
    1.提供了支持国际化的文本消息
    2.统一的资源文件读取方式
    3.已在监听器中注册的bean的事件


#锁-https://zhuanlan.zhihu.com/p/139021371 https://www.jianshu.com/p/17be890865e7?utm_campaign=maleskine
1、偏向锁、轻量级锁、自旋锁、重量级锁的转化

7、偏向锁/轻量级锁/重量级锁：

    这三种锁的状态是针对Synchronized而引入的，通过对象监控在对象头中的字段来表明状态
    偏向锁：指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价
    轻量级锁：指当锁是偏向锁时，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能
    重量级锁：指当锁是轻量级锁时，另一个线程虽然自旋，但自旋不会一直持续下去，当自旋到一定次数时，还没获取到锁，就会进入阻塞，该锁膨胀为重量级锁，重量级锁会让其他申请的线程进入阻塞，性能降低
    8、自旋锁：
    自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU

2、读写锁的实现原理

    读写锁的特点是：同一时刻允许多个线程对共享资源进行读操作；同一时刻只允许一个线程对共享资源进行写操作；当进行写操作时，同一时刻其他线程的读操作会被阻塞；当进行读操作时，同一时刻所有线程的写操作会被阻塞。对于读锁而言，由于同一时刻可以允许多个线程访问共享资源，进行读操作，因此称它为共享锁；而对于写锁而言，同一时刻只允许一个线程访问共享资源，进行写操作，因此称它为排他锁。
    读写锁不支持锁升级，支持锁降级。锁升级指的是线程获取到了读锁，在没有释放读锁的前提下，又获取写锁。锁降级指的是线程获取到了写锁，在没有释放写锁的情况下，又获取读锁。
     读写锁同时拥有读锁和写锁，且读共享、写及读写互斥， 当读取数据时用读锁，当没有线程获取到写锁或获取写锁是当前线程时能获取到读锁，多个线程可同时获取到读锁；当写数据时用写锁，当没有线程获取到读锁时，可以获取到写锁，最多只有一个线程能获取到写锁，若当前线程获取到读锁必须要先释放才能获取到写锁。
     
     基于AQS（抽象队列同步器，有一个voliate int state变量和互斥/共享获取、释放锁方法），Java 读写锁用state的高16位表示读锁的线程数，低16位表示写锁的重入数。其中读锁类中的Sync实现共享获取、释放锁方法，写锁类中Sync实现互斥获取、释放锁方法。
     
3、Aqs原理

4、CAS原理

#mysql数据库
1、数据库索引为什么用B+树
    数据库使用B+树肯定是为了提升查找效率。
    答1：B树在提高了IO性能的同时并没有解决元素遍历的我效率低下的问题，正是为了解决这个问题，B+树应用而生。B+树只需要去遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作或者说效率太低。
    答2：1、B+树的磁盘读写代价更低 B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对IO读写次数就降低了。
         2、B+树的查询效率更加稳定 由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。
         3、由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在区间查询的情况，所以通常B+树用于数据库索引。

2、分库分表场景-https://www.cnblogs.com/xdyixia/p/9429475.html https://zhuanlan.zhihu.com/p/144433597 https://zhuanlan.zhihu.com/p/137706956 https://blog.csdn.net/kefengwang/article/details/81213050 https://segmentfault.com/a/1190000020255513 https://www.jianshu.com/p/3dbdd12a7ed7
    分表：-横分纵分
    对于访问极为频繁且数据量巨大的单表（百万到千万级别）来说，我们首先要做的就是减少单表的记录条数，以便减少数据查询所需要的时间，提高数据库的吞吐，这就是所谓的分表！
    
    分库：-横分纵分
    分表能够解决单表数据量过大带来的查询效率下降的问题，但是，却无法给数据库的并发处理能力带来质的提升。
    面对高并发的读写访问，当数据库master服务器无法承载写操作压力时，不管如何扩展slave服务器，此时都没有意义了。
　　 因此，我们必须换一种思路，对数据库进行拆分，从而提高数据库写入能力，这就是所谓的分库!
　　 与分表策略相似，分库可以采用通过一个关键字取模的方式，来对数据访问进行路由

    总的来说，优先考虑分区。当分区不能满足需求时，开始考虑分表，合理的分表对效率的提升会优于分区。
    
    垂直分库-->水平分库-->读写分离 https://www.jianshu.com/p/3dbdd12a7ed7
    
3、慢查询场景
    表索引不合理
    表中存在大尺寸数据字段
    sql语句使用不当-使用LIKE关键字的查询语句

# 消息队列-https://www.cnblogs.com/xiapu5150/p/9927323.html
0、消息中间件如何保证高可用的-https://www.jianshu.com/p/2da7e4b39ceb
        
1、RocketMq的事务消息是怎么实现的
    分为两个逻辑：正常事务消息的发送及提交、事务消息的补偿流程
    事务消息发送及提交：
        发送消息（half消息）
        服务端响应消息写入结果
        根据发送结果执行本地事务（如果写入失败，此时half消息对业务不可见，本地逻辑不执行）
        根据本地事务状态执行Commit或者Rollback（Commit操作生成消息索引，消息对消费者可见）
    补偿流程：
        对没有Commit/Rollback的事务消息（pending状态的消息），从服务端发起一次“回查”
        Producer收到回查消息，检查回查消息对应的本地事务的状态
        根据本地事务状态，重新Commit或者Rollback
        补偿阶段用于解决消息Commit或者Rollback发生超时或者失败的情况。
2、kafka与mq对比-https://www.cnblogs.com/csuliujia/p/9379402.html
    架构方面：
        RabbitMQ遵循AMQP协议，RabbitMQ的broker由Exchange,Binding,queue组成，其中exchange和binding组成了消息的路由键；客户端Producer通过连接channel和server进行通信，Consumer从queue获取消息进行消费（长连接，queue有消息会推送到consumer端，consumer循环从输入流读取数据）。rabbitMQ以broker为中心；有消息的确认机制。
        kafka遵从一般的MQ结构，producer，broker，consumer，以consumer为中心，消息的消费信息保存的客户端consumer上，consumer根据消费的点，从broker上批量pull数据；无消息确认机制。
    吞吐量：
        rabbitMQ在吞吐量方面稍逊于kafka，他们的出发点不一样，rabbitMQ支持对消息的可靠的传递，支持事务，不支持批量的操作；基于存储的可靠性的要求存储可以采用内存或者硬盘。
        kafka具有高的吞吐量，内部采用消息的批量处理，zero-copy机制，数据的存储和获取是本地磁盘顺序批量操作，具有O(1)的复杂度，消息处理的效率很高。
    可用性方面：
        rabbitMQ支持miror的queue，主queue失效，miror queue接管。
        kafka的broker支持主备模式。
    在集群负载均衡方面：
        rabbitMQ的负载均衡需要单独的loadbalancer进行支持。
        kafka采用zookeeper对集群中的broker、consumer进行管理，可以注册topic到zookeeper上；通过zookeeper的协调机制，producer保存对应topic的broker信息，可以随机或者轮询发送到broker上；并且producer可以基于语义指定分片，消息发送到broker的某分片上。
        
3、RabbitMq怎么保证消息的可靠性-https://www.cnblogs.com/linjiqin/p/12683076.html
    (1)开启confirm
    (2)开启RabbitMQ的持久化(交换机、队列、消息)
    (3)关闭RabbitMQ的自动ack(改成手动)
    (4)配置消费重试次数，消费重试间隔时间等
4、Kafka为什么可以保证exactly-Once（即使 producer 重试发送消息）
    1、幂等-partition内部的exactly-once顺序语义 发送到Kafka的每批消息将包含一个序列号，该序列号用于重复数据的删除
    2、事务-跨partition的原子性写操作
5、Kafka怎么保证的高并发高可用
    -kafka
    producer端：
        1、ack=-1 消息发送到leader broker，并且成功写入所有isr的follow 副本才会认为消息发送成功，可靠性最高
        2、控制消息生产速率，防止发送线程跟不上生产线程，buffer打满，导致OOM，比如使用阻塞队列方式来减缓
        3、消息生产时进行持久化到DB或者本地，消息发送成功进行callback删除
    broker端：
        1、通过调节磁盘刷盘机制降低消息丢失概率，同步刷盘/异步刷盘频率提高，减少刷盘量
        2、通过多副本机制来保证
    consumer端：
        1、消费端关闭自动提交改为手动提交，消息成功消费后手动提交offset

# JVM调优-https://www.jianshu.com/p/0e32d7b4c064 https://juejin.cn/post/6896035896916148237
1、CMS和G1回收算法的过程-https://blog.csdn.net/wufaliang003/article/details/80684379

https://img2020.cnblogs.com/other/1218593/202006/1218593-20200617151347151-1115053251.webp

    CMS收集器是基于标记清除算法的一种并发的，低停顿的收集器，值得注意的一点是，CMS只是低停顿而不是没有停顿
    CMS分为以下四步：
    l、初始标记
    2、并发标记
    3、重新标记
    4、并发清除
    标记-清除算法导致的空间碎片 CMS是一款基于“标记-清除”算法实现的收集器，这意味着收集结束时会有大量空间碎片产生。
    空间碎片过多时，将会给大对象分配带来很大麻烦，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象。
    
    G1是一个并行回收器，它把堆内存分割为很多不相关的区间，每个区间可以属于老年代或者年轻代，并且每个年龄代区间可以是物理上不连续的。
    老年代区间这个设计理念本身是为了服务于并行后台线程，这些线程的主要工作是寻找未被引用的对象，而这样就会产生一种现象，
    即某些区间的垃圾（未被引用对象）多于其它的区间。垃圾回收时都是需要停下应用程序的，不然就没办法防止应用程序的干扰。
    G1 GC可以集中精力在垃圾最多的区间上，并且只费一点点时间就可以清空这些区间的垃圾，腾出完全空闲的区间。
    由于这种方式的侧重点在于处理垃圾最多的区间，所以我们给G1一个名字：垃圾优先（Garbage First）。
    G1内部有四个操作阶段：
    l、初始标记；
    2、并发标记；
    3、最终标记；
    4、筛选回收；
    空间整合 G1从整体来看是基于“标记-整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的。
    这意味着G1运行期间不会产生内存空间碎片，收集后能提供规整的可用内存。此特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。

2、Outofmemory的场景
    堆内存太小，无法满足应用的需 要
    内存泄漏，泄漏的内存被hold住，无法使用。
    Finalizer线程清理实现了finalize()方法的对象速度慢于生成这些对象的速度。
    数组对象太大， 无法载入堆内存中
    
3、FullGC和OutOfMemory有什么区别，怎么排查
4、Jvm调优的工具和命令-https://zhuanlan.zhihu.com/p/63102801
    关于性能监控这块的工具有linux的top指令及查看进程相关指令，jinfo，jps，jstat，jmap，jstack，jconsole。
    top指令：查看当前所有进程的使用情况，CPU占有率，内存使用情况，服务器负载状态等参数。除此之外它还是个交互命令，使用可参考完全解读top。
    jps：与linux上的ps类似，用于查看有权访问的虚拟机的进程，可以查看本地运行着几个java程序，并显示他们的进程号。当未指定hostid时，默认查看本机jvm进程。
    jinfo：可以输出并修改运行时的java 进程的一些参数。
    jstat：可以用来监视jvm内存内的各种堆和非堆的大小及其内存使用量。jstat -gc pid 3000
    jstack：堆栈跟踪工具，一般用于查看某个进程包含线程的情况。
    jmap：打印出某个java进程（使用pid）内存内的所有对象的情况。一般用于查看内存占用情况。jmap -dump:format=b,file=temp.dump pid。保留现场
    jconsole：一个java GUI监视工具，可以以图表化的形式显示各种数据。并可通过远程连接监视远程的服务器的jvm进程。
    
5、JVM调优经验-结合gc日志、内存监控、使用的垃圾收集器
    1、-Xms -Xmx设置为同样大小
    2、-XX:PermSize=256m -XX:MaxPermSize 一般为256m（jdk1.7）
    3、-XX:ThreadStackSize=512（防止出现StackOverflowError）
    4、-XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=256m（jdk1.8）
    5、-Xmn 响应时间优先的应用尽可能设大（老年代使用并发收集器） 吞吐量优先的也尽可能设大（新生代）
    6、增大新生代空间来降低MinorGC频率
    7、由于堆内存空间不足或老年代对象太多，会触发 Full GC，频繁的 Full GC 会带来上下文切换，增加系统的性能开销 降低Full GC频率
        减少创建大对象
        增大堆内存的空间
    8、选择合适的GC回收器
        如果要求每次操作的响应时间必须在 500ms 以内。这个时候我们一般会选择响应速度较快的 GC 回收器，
        堆内存比较小的情况下（<6G）选择 CMS（Concurrent Mark Sweep）
        回收器和堆内存比较大的情况下（>8G）G1 回收器.
    9、新生代设置越大，老年代就越小，Full GC频率就越高，但Full GC时间越短；相反新生代设置越小，老年代就越大，Full GC频率就越低，但每次Full GC消耗的时间越大
       -Xms和-Xmx的值设置成相等
       新生代尽量设置大一些，让对象在新生代多存活一段时间，每次Minor GC 都要尽可能多的收集垃圾对象，防止或延迟对象进入老年代的机会，以减少应用程序发生Full GC的频率。
       老年代如果使用CMS收集器，新生代可以不用太大，因为CMS的并行收集速度也很快，收集过程比较耗时的并发标记和并发清除阶段都可以与用户线程并发执行。
       
        
    
6、JVM-双亲委派机制
    双亲委派机制得工作过程：
    1-类加载器收到类加载的请求；
    2-把这个请求委托给父加载器去完成，一直向上委托，直到启动类加载器；
    3-启动器加载器检查能不能加载（使用findClass()方法），能就加载（结束）；否则，抛出异常，通知子加载器进行加载。
    4-重复步骤三；
    
    父类加载器能找到的类，子加载器就没有机会加载
    
    为什么要这么做呢？
    如果没有使用双亲委派模型，由各个类加载器自行加载的话，如果用户自己编写了一个称为java.lang.Object的类，并放在程序的ClassPath中，那系统将会出现多个不同的Object类， Java类型体系中最基础的行为就无法保证。应用程序也将会变得一片混乱。
 
    委托机制的意义
    防止内存中出现多份同样的字节码
    比如两个类A和类B都要加载System类：
    如果不用委托而是自己加载自己的，那么类A就会加载一份System字节码，然后类B又会加载一份System字节码，这样内存中就出现了两份System字节码。
    如果使用委托机制，会递归的向父类查找，也就是首选用Bootstrap尝试加载，如果找不到再向下。这里的System就能在Bootstrap中找到然后加载，如果此时类B也要加载System，也从Bootstrap开始，此时Bootstrap发现已经加载过了System那么直接返回内存中的System即可而不需要重新加载，这样内存中就只有一份System的字节码了。

7、JVM调优工具-
    1、JPS可以查看虚拟机启动的所有进程、执行主类的全名、JVM启动参数，比如当执行了
        jps -l 可看到下面的JPSTest类的pid为31354，加上-v参数还可以看到JVM启动参数。
    2、jstat监视虚拟机信息
        jstat -gc pid 500 10 ：每500毫秒打印一次Java堆状况（各个区的容量、使用容量、gc时间等信息），打印10次
    3、jmap查看堆内存信息 
        jmap -histo <pid>可以打印出当前堆中所有每个类的实例数量和内存占用
    4、利用jconsole、jvisualvm、mat分析内存信息
    5、分析堆转储快照
        “-XX:+HeapDumpOnOutOfMemory” 参数可以在程序发生内存溢出时dump出当前的内存快照
        jmap命令随时dump出当时内存状态的快照信息
8、cms G1
    CMS收集器
        CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器,作用于老年代，这是因为CMS收集器工作时，GC工作线程与用户线程可以并发执行，以此来达到降低收集停顿时间的目的。
        CMS收集器是基于标记清除算法的一种并发的，低停顿的收集器，值得注意的一点是，CMS只是低停顿而不是没有停顿
    cms收集器优点：
        并发收集、低停顿。
    cms收集器缺点：
        CMS收集器对CPU资源非常敏感。
        CMS收集器无法处理浮动垃圾（Floating Garbage）。
        算法是标记清除，会产生磁盘碎片
        新生代配合ParNewGC使用，存在STW问题。 --- 时间不可控，如果heap很大，可能GC时间很大，影响线上服务
    
    G1收集器
        G1重新定义了堆空间，打破了原有的分代模型，将堆划分为一个个区域。这么做的目的是在进行收集时不必在全堆范围内进行，这是它最显著的特点。
        区域划分的好处就是带来了停顿时间可预测的收集模型：用户可以指定收集操作在多长时间内完成。即G1提供了接近实时的收集特性。
        一款面向服务器的垃圾收集器，主要针对配备多颗处理器及大容量内存(大概6G以上)的机器；
        G1从jdk7开始，jdk9被设为默认垃圾收集器；目标就是彻底替换掉CMS
    G1收集器优点：
        并行与并发
        分代收集
        空间整合-与CMS的标记-清除算法不同，G1从整体来看是基于标记-整理算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的。但无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。
        可预测gc停顿时间-这是G1相对于CMS的一个优势，降低停顿时间是G1和CMS共同的关注点。
        可根据用户设置停顿时间，制定回收计划(但是也可能存在超出用户的停顿时间).  --- 最主要的目标
    G1收集器缺点：
        G1 需要记忆集 (具体来说是卡表)来记录新生代和老年代之间的引用关系，
        这种数据结构在 G1 中需要占用大量的内存，可能达到整个堆内存容量的 20% 甚至更多。
        而且 G1 中维护记忆集的成本较高，带来了更高的执行负载，影响效率。
    
    对于打算从CMS或者ParallelOld收集器迁移过来的应用，按照官方 的建议，如果发现符合如下特征，可以考虑更换成G1收集器以追求更佳性能：
        实时数据占用了超过半数的堆空间；
        对象分配率或“晋升”的速度变化明显；
        期望消除耗时较长的GC或停顿（超过0.5——1秒）。
    
    G1和CMS适用场景
        实际用cms的挺多，也有更多经验；
        如果都不熟，先看看g1能否达到你的延迟、吞吐目标；
        还有基础配置，如堆大小，比较大，比如16g以上，建议优先g1；30G以上慎用CMS
        如果gc是stw（执行垃圾回收算法出现全局暂停现象）时间过长，一般也是通过G1来解决
        按照《深入理解Java虚拟机》作者的说法，CMS 在小内存应用上的表现要优于 G1，而大内存应用上 G1 更有优势，大小内存的界限是6GB到8GB。
          
5、服务响应慢怎么排查优化
    1.是不是资源层面的瓶颈？
    2.是不是缓存没添加，如果加了，是不是热点数据导致负载不均衡？
    3.是不是有依赖于第三方接口？
    4.是不是接口涉及业务太多，导致程序跑很久？
    5.是不是sql层面的问题导致的等待时机加长，进而拖慢接口？
    6.网络层面的原因？带宽？DNS解析？
    7.代码确实差？？？
    
    解决：
    1.资源紧张，加机器，干上去，负载均衡搞起来
    2.加缓存可以解决的问题都不是什么大问题，存在热点数据可以将某几个热点单独出来用专门的机器进行处理，不要因为局部影响整体
    3.一方面与第三方沟通接口响应问题，另一方面超时时间注意把控，如果可以非核心业务能异步久异步掉。
    4.把非核心的业务进行异步化操作。记住如果代码层面是非核心业务，但是会影响用户感知，需要慎重决定是否异步。
    5.如果是代码不良导致加锁了，尽量优化索引或sql语句，让锁的级别最小（到行），一般来说到行差不多了。如果是单个sql跑慢了，需要分析是不是索引没加或者sql选的索引错了，索引该加的就加了，该force index也加了。
    6.网路原因，需要联系运营商一起商量下怎么解决，单方面比较难有大的优化。
    7.代码确实差，那也无药可救了。我选择狗带。

# 其他
1、以前工作中难度最高和提升最大的项目
2、mysql复合索引的数据结构
    首先我们创建的idx_t1_bcd(b,c,d)索引，相当于创建了(b)、（b、c）（b、c、d）三个索引，看完下面你就知道为什么相当于创建了三个索引。
    我们看，联合索引是首先使用多列索引的第一列构建的索引树，用上面idx_t1_bcd(b,c,d)的例子就是优先使用b列构建，当b列值相等时再以c列排序，若c列的值也相等则以d列排序
    这就像我们的电话本一样，有名和姓以及电话，名和姓就是联合索引。在姓可以以姓的首字母排序，姓的首字母相同的情况下，再以名的首字母排序。
    我们知道名和姓是很快就能够从姓的首字母索引定位到姓，然后定位到名，进而找到电话号码，因为所有的姓从上到下按照既定的规则（首字母排序）是有序的，而名是在姓的首字母一定的条件下也是按照名的首字母排序的，但是整体来看，所有的名放在一起是无序的，所以如果只知道名查找起来就比较慢，因为无法用已排好的结构快速查找。
    到这里大家是否明白了为啥会有最左前缀匹配原则了吧。
    
3、mysql可重复读的实现原理
    MySQL默认的隔离级别是可重复读，即：事务A在读到一条数据之后，此时事务B对该数据进行了修改并提交，那么事务A再读该数据，读到的还是原来的内容。 那么MySQL可重复读是如何实现的呢？
    使用的的一种叫MVCC的控制方式 ，即Mutil-Version Concurrency Control,多版本并发控制，类似于乐观锁的一种实现方式
    实现方式：
        InnoDB在每行记录后面保存两个隐藏的列来，分别保存了这个行的创建时间和行的删除时间。这里存储的并不是实际的时间值,而是系统版本号，当数据被修改时，版本号加1
        在读取事务开始时，系统会给当前读事务一个版本号，事务会读取版本号<=当前版本号的数据
        此时如果其他写事务修改了这条数据，那么这条数据的版本号就会加1，从而比当前读事务的版本号高，读事务自然而然的就读不到更新后的数据了

4、分布式系统的一致性-https://blog.csdn.net/zheng0518/article/details/51194942
    1、强一致性-不保证可用性
    2、弱一致性-不承偌立即可以读到最新写入值
    3、最终一致性-系统最终会返回上一次更新操作的值
    在工程实践上，为了保障系统的可用性，互联网系统大多将强一致性需求转换成最终一致性的需求，并通过系统执行幂等性的保证，保证数据的最终一致性
    1. 规避分布式事务——业务整合
        优点：解决（规避）了分布式事务。
        缺点：显而易见，把本来规划拆分好的业务，又耦合到了一起，业务职责不清晰，不利于维护。
    2. 经典方案 - eBay 模式
        此方案的核心是将需要分布式处理的任务通过消息日志的方式来异步执行。消息日志可以存储到本地文本、数据库或消息队列，再通过业务规则自动或人工发起重试。人工重试更多的是应用于支付场景，通过对账系统对事后问题的处理。
    3. 将分布式事务转换为多个本地事务，然后依靠重试等方式达到最终一致性。
    
    
5、http请求到Tomcat的整体流程
6、怎么保证分布式系统的稳定性-https://zhuanlan.zhihu.com/p/150377297?from_voters_page=true
    1、服务分级
    2、优雅降级
    3、开关可控
    4、服务监视、统计、报表
    5、应急预案
    6、异常兜底
7、MVCC原理，怎么解决的幻读问题
什么是MCVV：
    多版本并发控制。InnoDB为每行记录添加了一个版本号（系统版本号），每当修改数据时，版本号加一。
    在读取事务开始时，系统会给事务一个当前版本号，事务会读取版本号<=当前版本号的数据，这时就算另一个事务插入一个数据，
    并立马提交，新插入这条数据的版本号会比读取事务的版本号高，因此读取事务读的数据还是不会变。解决了幻读的问题。

8、个人优缺点
9、api接口如何保证幂等性-https://blog.csdn.net/ppwwp/article/details/107735205 https://blog.csdn.net/u011635492/article/details/81058153?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.not_use_machine_learn_pai&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.not_use_machine_learn_pai
    1、全局唯一id-mysql redis
    2、去重表-并且把唯一标识作为唯一索引，在我们实现时，把创建支付单据和写入去去重表，放在一个事务中，如果重复创建，数据库会抛出唯一约束异常，操作就会回滚。
    3、多版本控制-这种方法适合在更新的场景中，比如我们要更新商品的名字，这时我们就可以在更新的接口中增加一个版本号，来做幂等 update table_xxx set name=#name#,version=version+1 where id=#id# and version=#version# 
    4、状态机控制-这种方法适合在有状态机流转的情况下，比如就会订单的创建和付款，订单的付款肯定是在之前，这时我们可以通过在设计状态字段时，使用int类型，并且通过值类型的大小来做幂等，比如订单的创建为0，付款成功为100。付款失败为99
        update `order` set status=#{status} where id=#{id} and status<#{status}
# 微服务-https://baijiahao.baidu.com/s?id=1655329799036379323&wfr=spider&for=pc

、ArrayList 与 LinkedList 的不区别？
    
    最明显的区别是 ArrrayList 底层的数据结构是数组，支持随机访问，而 LinkedList 的底层数据结构书链表，不支持随机访问。使用下标访问一个元素， ArrayList 的时间复杂度是 O(1)，而 LinkedList 是 O(n)

Java 中，抽象类与接口之间有什么不同？
    
    Java 中，抽象类和接口有很多不同之处，但是最重要的一个是 Java 中限制一个 类只能继承一个类，但是可以实现多个接口。抽象类可以很好的定义一个家族类 的默认行为，而接口能更好的定义类型，有助于后面实现多态机制。

说出 5 个 JDK 1.8 引入的新特性？
    
       Java 8 在 Java 历史上是一个开创新的版本，下面 JDK 8 中 5 个主要的特性： 
       Lambda 表达式，允许像对象一样传递匿名函数 
       Stream API，充分利用现代多核 CPU，可以写出很简洁的代码 
       Date 与 Time API，最终，有一个稳定、简单的日期和时间库可供你使用 
       扩展方法，现在，接口中可以有静态、默认方法。 
       重复注解，现在你可以将相同的注解在同一类型上使用多次。

-----------------------------------------------------------------------------------------------
1、hashmap在什么情况下会扩容，那些操作会导致扩容
    java 7中的hashmap扩容机制（需要同时满足这两个条件）（先判断是否需要扩容，再插入）：
    1、存放新值的时候当前已有元素的个数必须大于等于阈值
    2、存放新值的时候当前存放数据发生hash碰撞（当前key计算的hash值换算出来的数组下标位置已经存在值）
    采用头插法进行
    注：使用头插法在多线程扩容的时候可能会导致循环指向，从而在获取数据get()的时候陷入死循环，到是线程执行无法结束
    
    java 8中的扩容机制（先进行插入，插入完成再判断是否需要扩容；）：
    1、当前存放新值（注意不是替换已有元素位置时）的时候已有元素的个数大于等于阈值（已有元素等于阈值，下一个存放后必然触发扩容机制）
    2、 存入数据到某一条链表时，此时该链表数据个数大于8，且总数量小于64即发生扩容
    
    尾插法：元素插入的时候都是从尾部插入，这样新进来的就在头部，后进来的就在尾部，扩容的时候，先进来的先出，指向next和扩容前方向一致，所以不存在循环指向的问题。
    当链表长度大于8，且总数据量大于64的时候，链表就会转化成红黑树 如果数据量小于64则只有数组+链表，如果数据量大于64，且某一个数组下标数据量大于8，那么该处即为红黑树。
    
    第一次添加元素的时候，默认初期长度为16，当往map中继续添加元素的时候，通过hash值跟数组长度取“与”来决定放在数组的哪个位置，如果出现放在同一个位置的时候，
    优先以链表的形式存放，在同一个位置的个数又达到了8个（代码是>=7,从0开始，及第8个开始判断是否转化成红黑树），如果数组的长度还小于64的时候，则会扩容数组。
    如果数组的长度大于等于64的话，才会将该节点的链表转换成树。在扩容完成之后，如果某个节点的是树，同时现在该节点的个数又小于等于6个了，则会将该树转为链表。

2、hashmap检查到hash冲突后，将链表插入链表的末端还是开头
    java 7 头插法 多线程环境下扩容容易出现循环链表 导致查询的时候陷入死循环
    java 8 尾插法 扩容的时候先来的先出 链表的指向next与扩容方向一致，所以不存在循环指向问题
    
3、1.8采用了红黑树，讲讲红黑树的特性，为什么人家一定要用红黑树而不是AVL，B数之类的
    采用红黑树是为了加快检索速度，提高查询效率 此数据结构的平均查询效率为Ｏ(long n) 。
    红黑树（Red Black Tree） 是一种自平衡二叉查找树， 红黑树和AVL树类似，都是在进行插入和删除操作时通过特定操作保持二叉查找树的平衡，
    从而获得较高的查找性能。它虽然是复杂的，但它的最坏情况运行时间也是非常良好的，并且在实践中是高效的： 它可以在O(log n)时间内做查找，
    插入和删除，这里的n 是树中元素的数目。
     
    红黑树和AVL树都是最常用的平衡二叉搜索树，它们的查找、删除、修改都是O(lgn) time
    AVL树和红黑树有几点比较和区别：
    （1）AVL树是更加严格的平衡，因此可以提供更快的查找速度，一般读取查找密集型任务，适用AVL树。
    （2）红黑树更适合于插入修改密集型任务。
    （3）通常，AVL树的旋转比红黑树的旋转更加难以平衡和调试。
    1）AVL以及红黑树是高度平衡的树数据结构。它们非常相似，真正的区别在于在任何添加/删除操作时完成的旋转操作次数。
    （2）两种实现都缩放为a O(lg N)，其中N是叶子的数量，但实际上AVL树在查找密集型任务上更快：利用更好的平衡，树遍历平均更短。另一方面，插入和删除方面，AVL树速度较慢：需要更高的旋转次数才能在修改时正确地重新平衡数据结构。
    （3）在AVL树中，从根到任何叶子的最短路径和最长路径之间的差异最多为1。在红黑树中，差异可以是2倍。
    （4）两个都给O（log n）查找，但平衡AVL树可能需要O（log n）旋转，而红黑树将需要最多两次旋转使其达到平衡（尽管可能需要检查O（log n）节点以确定旋转的位置）。旋转本身是O（1）操作，因为你只是移动指针。

    在CurrentHashMap中是加锁了的，实际上是读写锁，如果写冲突就会等待，如果插入时间过长必然等待时间更长，而红黑树相对AVL树他的插入更快！
    

3、HashMap的put操作过程
 思路如下：
    1、如果HashMap没有被初始化过，则初始化
    2、对key求Hash值，然后在计算下标
    3、如果没有碰撞则直接放入桶中
    4、如果碰撞了，以链表的方式链接到后面（尾插法-jdk1.8）
    5、如果链表长度超过阈值8，就把链表转为红黑树
    6、如果链表长度低于6，就把红黑树转回链表
    7、如果节点已经存在就替换旧值
    8、如果桶满了（16*加载因子0.75）， 就需要resize（扩容两倍后重排-位置不变或索引+旧容量大小）
    
4、linux 怎么查看系统负载的情况
    uptime:查看平均负载
    w：
        第1行：与uptime命令相同
        第2行以下：当前登录的用户列表
    top：
        第1行：与uptime命令相同
        第2行：进程数信息
    iostat：查看系统区分的I/O使用情况。
    iotop:是各个进程的I/O情况，对于定位I/O操作较重的进程有较大的作用。
    sar:
        sar -u 查看当天CPU使用情况
        sar -r 查看当天内存使用情况
        sar -b 查看当天IO统计记录
        
5、请详细描述SpringMvc处理请求的全过程
    1、整个过程开始于客户端发起的http的请求，web服务器接收到这个请求，如果匹配DispatcherServlet(分发器)的请求映射路径，web容器就交给DispatcherServlet处理。
    2、DispatcherServlet把接受到的请求，根据请求的HandlerMapping信息找到对应的处理请求的处理器（Handler）。
    3、通过HandlerAdapter封装后的Handler，在用统一的适配器接口调用Handler。
    4、处理器完成业务逻辑处理之后，将返回一个ModelAndView给DispatcherServlet。
    5、DispatcherServlet借由ViewResolver完成逻辑视图名到真实视图对象的解析工作。因为ModelAndView是逻辑视图名。
    6、DispatcherServlet是用View对象对ModelAndView中的模型数据进行视图渲染。
    7、最终反馈给客户端。
    
6、spring一个bean装配过程
    1. 实例化;
    2. 设置属性值;
    3. 如果实现了BeanNameAware接口,调用setBeanName设置Bean的ID或者Name;
    4. 如果实现BeanFactoryAware接口,调用setBeanFactory 设置BeanFactory;
    5. 如果实现ApplicationContextAware,调用setApplicationContext设置ApplicationContext
    6. 调用BeanPostProcessor的预先初始化方法;
    7. 调用InitializingBean的afterPropertiesSet()方法;
    8. 调用定制init-method方法；
    9. 调用BeanPostProcessor的后初始化方法;
7、讲讲AtomicInteger 为什么要用CAS（Compare And Swap）（CAS有三个操作数：内存值V、旧的预期值A、要修改的值B，当且仅当预期值A和内存值V相同时（条件），将内存值修改为B并返回true，否则条件不符合返回false。条件不符合说明该变量已经被其它线程更新了。）而不是synchronized
    CAS这是一种乐观锁的思路，它相信在它修改之前，没有其它线程去修改它；CAS容易出现aba问题 ，除了比较值还需要比较版本号，加个版本号就可以解决，AtomicStampedReference就是用版本号实现cas机制。
    而Synchronized是一种悲观锁，它认为在它修改之前，一定会有其它线程去修改它，悲观锁效率很低
    
8 JVM老年代和新生代的比例
    java1.8 新生代：老年代=1:2
    
9、YGC和FGC发生的具体场景
    YGC:
    edn空间不足,执行 young gc
    FGC:
    调用System.gc()方法
    老年代空间不足
    PermGen或Metaspace空间不足
    Minor GC晋升到老年代的平均大小大于老年代的剩余空间

10、jstack，jmp，jps，jstat,jutil分别的意义？如何线上排查JVM的相关问题
    jstack 用来查看某个Java进程内的线程堆栈信息 -查看线程
    jmap 用来查看堆内存使用状况，一般结合jhat使用。-查看内存
    jstat classloader，compiler，gc相关信息。可以时时监控资源和性能 
    jps 主要输出JVM 运行的进程状态信息
    jstat JVM统计监测工具-性能分析
    hprof 展现CPU使用率，统计堆内存使用情况。
    
    线上问题排查：
    CPU飙高：-首先找到 CPU 飚高的那个 Java 进程，因为你的服务器会有多个 JVM 进程。然后找到那个进程中的 “问题线程”，最后根据线程堆栈信息找到问题代码。最后对代码进行排查。
    内存问题排查：-内存的问题就是 GC 的问题，因为 Java 的内存由 GC 管理。有2种情况，一种是内存溢出了，一种是内存没有溢出，但 GC 不健康。
    1、通过相关工具 比如MAT查看dump文件
    通常一个健康的 GC 是什么状态呢？根据楼主的经验，YGC 5秒一次左右，每次不超过50毫秒，FGC 最好没有，CMS GC 一天一次左右。
    而 GC 的优化有2个维度，一是频率，二是时长。
    FGC 我们只能优化频率，无法优化时长，因为这个时长无法控制
    通常优化的点是 Old 区内存不够导致 FGC。如果 FGC 后还有大量对象，说明 Old 区过小，应该扩大 Old 区。
    如果 FGC 后效果很好，说明 Old 区存在了大量短命的对象，优化的点应该是让这些对象在新生代就被 YGC 掉，通常的做法是增大新生代，如果有大而短命的对象，通过参数设置对象的大小，不要让这些对象进入 Old 区，还需要检查晋升年龄是否过小。如果 YGC 后，有大量对象因为无法进入 Survivor 区从而提前晋升，这时应该增大 Survivor 区，但不宜太大。
    
    
11、接口如何处理重复请求
    设计防重按钮
    利用唯一请求编号去重-你可能会想到的是，只要请求有唯一的请求编号，那么就能借用Redis做这个去重——只要这个唯一请求编号在redis存在，证明处理过，那么就认为是重复的
    
    
12、单机上一个线程池正在处理服务 如果突然断电怎么办（正在处理和阻塞队列里的请求怎么处理）
    正在处理的实现事务功能，下次自动回滚。
    队列实现持久化储存，下次启动自动载入。
13、java反射 注解原理-https://blog.csdn.net/qq_41144667/article/details/105029604
14、java容器有哪些？哪些是同步容器 哪些是并发容器
    list set queue map collection
    常见同步容器：
        SynchronizedCollection
        SynchronizedSet
        SynchronizedList
        SynchronizedMap
        Hashtable
    常见并发容器：
        BlockingQueue
        BlockingDeque
        ConcurrentMap
        ConcurrentHashMap
        ConcurrentLinkedQueue
        ConcurrentLinkedDeque
        DelayQueue
    
        
15、ArrayList 和LinkedList的插入和访问的时间复杂度
    ArrayList 插入和访问时间复杂度为O(1)
    LinkedList 插入复杂度为O(1) 访问时间复杂度是O(n) 
    
16、新生代分那几个区，使用什么算法进行垃圾回收，为什么要使用这个算法
    新生代划分为一块较大的Eden空间和两块较小的Survivor空间（分别被命名为from和to），每次使用Eden空间和其中的一块Survivor空间。
    当触发一次YoungGC时，将Eden和Survivor中还存活的对象复制到另一块Survivor空间中，然后清理掉Eden和刚才使用过的Survivor空间。
    三者内存大小比例为8：1：1
    
    1.新生代：Eden+From Survivor+To Survivor
    2.老年代：OldGen
    3.永久代（方法区的实现） : PermGen----->替换为Metaspace(本地内存中)
    元空间没有使用堆内存，而是与堆不相连的本地内存区域。所以，理论上系统可以使用的内存有多大，元空间就有多大，所以不会出现永久代存在时的内存溢出问题。
    
    GC算法：
        标记清除：分为标记和清除两个部分：首先标记出所有需要回收的对象，这一过程在可达性分析过程中进行。在标记完之后统一回收所有被标记的对象
            会产生内存碎片，内存碎片太多会导致以后的程序运行中无法分配出较大的内存，从而不得不触发另外的垃圾回收
        复制算法：针对Java堆中的新生代内存垃圾回收
            复制算法将堆中可用的新生代内存按容量划分成大小相等的两块内存区域，每次只使用其中的一块区域。当其中一块内存区域需要进行垃圾回收时，会将此区域内还存活着的对象复制到另一块上面，然后再把此内存区域一次性清理掉。
            每次都是对整个新生代一半的内存区域进行内存回收，内存分配时也就不需要考虑内存碎片等复杂情况，只需要移动堆顶指针，按顺序分配即可。此算法实现简单，运行高效
        标记整理算法：针对老年代内存垃圾回收
            标记过程仍与”标记-清除”过程一致，但后续步骤不是直接对可回收对象进行清理，而是让所有存活对象都向一端移动，然后直接清理掉端边界以外的内存。不会产生内存碎片
        分代收集法：
            分代收集算法是目前大部分JVM的垃圾收集器采用的算法。它的核心思想是根据对象存活的生命周期将内存划分为若干个不同的区域。一般情况下将堆区划分为老年代（Tenured Generation）和新生代（Young Generation），老年代的特点是每次垃圾收集时只有少量对象需要被回收，而新生代的特点是每次垃圾回收时都有大量的对象需要被回收，那么就可以根据不同代的特点采取最适合的收集算法。
            目前大部分垃圾收集器对于新生代都采取Copying算法，因为新生代中每次垃圾回收都要回收大部分对象，也就是说需要复制的操作次数较少。而由于老年代的特点是每次回收都只回收少量对象，一般使用的是标记整理算法。

17、如何进入老年代呢？
    1、大对象直接进入老年代
    因为新生代是使用的复制算法，所以要尽量减少复制的内存，所以对象内存到一定的值后就会直接进入老年代。
    2、新生代对象年龄到一定程度后进入老年代
    每个对象会有一个Age的计数器，初始值为0，每经过一次GC并且存活，这个对象的Age就会加1，如果增加到一定程度（默认为15）。那么就会进入老年代中。
    3、动态对象年龄判定
    如果在新生代存活区中相同年龄所有对象大小的总和大于存活区的一半，年龄大于或等于该年龄的对象就会直接进入老年代。
    比如现在存活区有三个对象，Age分别为2、2、3。那么Age为3的这个对象就会进入老年代。

17、如何判断对象已经死亡
    1、引用计数法
        引用和对象是关联的，如果要操作对象，则必须用引用进行，因此，可以通过引用计数来判断对象是否可以回收。
        如果该对象被引用，计数器加1，不引用减1，如果计数器等于0，我们就认为没有引用指向该对象，可以将该对象回收，
    2、可达性分析
        通过一系列GC Roots对象作为起始点搜索，如果在GC Roots和一个对象之间没有可达路径，则认为该对象不在存活
17、hashmap和treemap什么区别？底层数据结构是什么
    HashMap：数组方式存储key/value，线程非安全，允许null作为key和value，key不可以重复，value允许重复，不保证元素迭代顺序是按照插入时的顺序，key的hash值是先计算key的hashcode值，
    然后再进行计算，每次容量扩容会重新计算所以key的hash值，会消耗资源，要求key必须重写equals和hashcode方法。
    默认初始容量16，加载因子0.75，扩容为旧容量乘2，查找元素快，如果key一样则比较value，如果value不一样，则按照链表结构存储value，就是一个key后面有多个value；

    TreeMap：基于红黑二叉树的NavigableMap的实现，线程非安全，不允许null，key不可以重复，value允许重复，存入TreeMap的元素应当实现Comparable接口或者实现Comparator接口，
    会按照排序后的顺序迭代元素，两个相比较的key不得抛出classCastException。主要用于存入元素的时候对元素进行自动排序，迭代输出的时候就按排序顺序输出
18、synchnized和lock什么区别，synchnized什么情况下是对象锁，什么时候是全局锁
    1.首先synchronized是java内置关键字，在jvm层面，Lock是个java类；
    2.synchronized无法判断是否获取锁的状态，Lock可以判断是否获取到锁；
    3.synchronized会自动释放锁(a 线程执行完同步代码会释放锁 ；b 线程执行过程中发生异常会释放锁)，Lock需在finally中手工释放锁（unlock()方法释放锁），否则容易造成线程死锁；
    4.用synchronized关键字的两个线程1和线程2，如果当前线程1获得锁，线程2线程等待。如果线程1阻塞，线程2则会一直等待下去，而Lock锁就不一定会等待下去，如果尝试获取不到锁，线程可以不用一直等待就结束了；
    5.synchronized的锁可重入、不可中断、非公平，而Lock锁可重入、可判断、可公平（两者皆可）
    6.Lock锁适合大量同步的代码的同步问题，synchronized锁适合代码少量的同步问题。
    
    synchnized关键字锁住对象，称为对象锁
    synchnized关键字锁住类，称为全局锁
    
19、公平锁与非公平锁的区别
    1.公平锁
    多个线程按照申请锁的顺序去获得锁，线程会直接进入队列去排队，永远都是队列的第一位才能得到锁。
    优点：所有的线程都能得到资源，不会饿死在队列中。
    缺点：吞吐量会下降很多，队列里面除了第一个线程，其他的线程都会阻塞，cpu唤醒阻塞线程的开销会很大。
    2.非公平锁
    多个线程去获取锁的时候，会直接去尝试获取，获取不到，再去进入等待队列，如果能获取到，就直接获取到锁。
    优点：可以减少CPU唤醒线程的开销，整体的吞吐效率会高点，CPU也不必取唤醒所有线程，会减少唤起线程的数量。
    缺点：你们可能也发现了，这样可能导致队列中间的线程一直获取不到锁或者长时间获取不到锁，导致饿死。


19、ThreadLocal是什么 底层如何实现 ？
    ThreadLocal是一个解决线程并发问题的一个类，用于创建线程的本地变量，我们知道一个对象的所有线程会共享它的全局变量，
    所以这些变量不是线程安全的，我们可以使用同步技术。但是当我们不想使用同步的时候，我们可以选择ThreadLocal变量。
    每个线程都会拥有他们自己的Thread变量，他们可以使用get/set方法去获取他们的默认值或者在线程内部改变他们的值。
    ThreadLocal实例通常是希望他们同线程状态关联起来是private static属性。
    
　　底层实现主要是存有一个map，以线程作为key，泛型作为value，可以理解为线程级别的缓存。每一个线程都会获得一个单独的map。

20、volitile的工作原理
    volatile的特性：
        volatile可见性：对一个volatile的读，总可以看到对这个变量最终的写；
        volatile原子性：volatile对单个读/写具有原子性（32位Long、Double），但是复合操作除外，例如：i++；
        jvm底层采用“内存屏障”来实现volatile语义。
    volatile的内存语义及实现：
　　     在JMM（Java内存模型）中，线程之间的通信采用共享内存来实现的。
    volatile内存语义是：
        当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值立即刷新到主内存中；
        当读一个volatile变量时，JMM会把该线程对应的本地内存设置为无效，直接从主内存中读取共享变量。
        
21、cas知道吗如何实现
    CAS是compare and swap，翻译过来就是比较并交换。维护三个变量值，一个是内存值V，一个是期望的旧的值A，一个是要更新的值B。
    更新一个变量的时候，只有当预期值A与内存V中的值相等的时候，才会执行更新操作，把内存V的值改为B。
    
   缺点：
    CPU开销过大，因为如果有很多线程一直在反复尝试更新一个变量，却又更新不成功时，就会一直自旋消耗CPU；
    不能保证代码块的原子性，它只能保证一个变量的原子性；
    ABA问题。（一个值从A变成B，又更新回A，普通CAS会误判通过检测。利用版本号机制可以解决ABA问题。）
        
22、线上频繁出现full gc如何处理，cpu使用率过高怎么办
    首先导出jstack和内存信息 然后重启系统 尽快保证系统可用性
    这种情况可能的原因主要有两种：
        代码中某个位置读取数据量较大，导致系统内存耗尽，从而导致 Full GC 次数过多，系统缓慢。
        代码中有比较耗 CPU 的操作，导致 CPU 过高，系统运行缓慢。
    对于 Full GC 较多的情况，其主要有如下两个特征：
        线上多个线程的 CPU 都超过了 100%，通过 jstack 命令可以看到这些线程主要是垃圾回收线程。
        通过 jstat 命令监控 GC 情况，可以看到 Full GC 次数非常多，并且次数在不断增加。
    首先我们可以使用 top 命令查看系统 CPU 的占用情况 
    1、top -Hp pid
    2、查到那个当前子线程的pid那个cpu最高 然后转换线程ID：printf "%x\n" pid1  输出 id
    3、定位cpu占用的线程：jstack pid|grep id -A 30
    4、查看当前线程gc 情况：jstat -gcutil pid 1000 10
    5、如果是内存溢出导致的系统慢 那么就通过jmap导出dump文件利用MAT内存分析工具进行分析
        
23、做过那些jvm优化，使用什么方法达到什么效果-https://www.cnblogs.com/andy-zhou/p/5327288.html
    分代收集：-不同的对象的生命周期是不一样的。因此，不同生命周期的对象可以采取不同的收集方式，以便提高回收效率。
        新生代：（存放生命周期比较短对象）复制算法
        老年代：（存放生命周期比较长对象）老年代中使用“标记-清除”或者“标记-整理”算法进行垃圾回收，回收次数相对较少，每次回收时间比较长。
        永久代：“标记-清除”或者“标记-整理”算法进行垃圾回收
        
    JVM调优目标：使用较小的内存占用来获得较高的吞吐量或者较低的延迟。
    JVM调优查询方法：
        ①系统运行日志
        ②堆栈错误信息-比如根据“java.lang.OutOfMemoryError: Java heap space”可以判断是堆内存溢出；根据“java.lang.StackOverflowError”可以判断是栈溢出；根据“java.lang.OutOfMemoryError: PermGen space”可以判断是方法区溢出等。
        ③GC日志-程序启动时用 -XX:+PrintGCDetails 和 -Xloggc:/data/jvm/gc.log 可以在程序运行时把gc的详细过程记录下来
        ④线程快照：顾名思义，根据线程快照可以看到线程在某一时刻的状态，当系统中可能存在请求超时、死循环、死锁等情况是，可以根据线程快照来进一步确定问题。通过执行虚拟机自带的“jstack pid”命令，可以dump出当前进程中线程的快照信息，
        ⑤堆转储快照：程序启动时可以使用 “-XX:+HeapDumpOnOutOfMemory” 和 “-XX:HeapDumpPath=/data/jvm/dumpfile.hprof”，当程序发生内存溢出时，把当时的内存快照以文件形式进行转储（也可以直接用jmap命令转储程序运行时任意时刻的内存快照），事后对当时的内存使用情况进行分析。
    JVM调优经验：
        1、jvm配置方面一般情况可以先用默认配置，在测试中结合GC日志，内存监控，使用垃圾回收器等进行合理的调整，当老年代内存过小时可能引起频繁FGC，当内存过大时FGC时间会特别长
        2、调优就是找答案过程 物理内存一定的情况下 ，新生代设置越大，老年代越小，FGC频率就越高，但FGC时间越短；相反新生代设置越小，老年代就越大，FGC频率越低，但每次FGC消耗的时间越大
        一般建议：
        1、-Xms和-Xmx的值设置成相等，堆大小默认为-Xms指定的大小，默认空闲堆内存小于40%时，JVM会扩大堆到-Xmx指定的大小；空闲堆内存大于70%时，JVM会减小堆到-Xms指定的大小。如果在Full GC后满足不了内存需求会动态调整，这个阶段比较耗费资源。
        2、新生代尽量设置大一些，让对象在新生代多存活一段时间，每次Minor GC 都要尽可能多的收集垃圾对象，防止或延迟对象进入老年代的机会，以减少应用程序发生Full GC的频率。
        3、老年代如果使用CMS收集器，新生代可以不用太大，因为CMS的并行收集速度也很快，收集过程比较耗时的并发标记和并发清除阶段都可以与用户线程并发执行。
        4、当出现StackOverflowError异常的时候说明栈中存储的数据比较多，需要适当调大-Xss这个值
        
        具体抽象建议：
        #年轻代大小选择
        响应时间优先：
            尽可能设大年轻代，直到接近系统的最低响应时间限制（根据实际情况选择）。在此种情况下，年轻代收集发生的频率也是最小的。同时，减少到达年老代的对象。
        吞吐量优先的应用：
            尽可能的设置大，可能到达Gbit的程度。因为对响应时间没有要求，垃圾收集可以并行进行，一般适合8CPU以上的应用。
        #老年大大小选择
        响应时间优先：老年代使用并发收集器，
        
        吞吐量优先的应用
            一般吞吐量优先的应用都有一个很大的年轻代和一个较小的年老代。原因是，这样可以尽可能回收掉大部分短期对象，减少中期的对象，而年老代尽存放长期存活对象。
        
        较小堆引起的碎片问题
            因为年老代的并发收集器使用标记、清除算法，所以不会对堆进行压缩。当收集器回收时，他会把相邻的空间进行合并，这样可以分配给较大的对象。但是，当堆空间较小时，运行一段时间以后，就会出现“碎片”，如果并发收集器找不到足够的空间，那么并发收集器将会停止，然后使用传统的标记、清除方式进行回收。如果出现“碎片”，可能需要进行如下配置：
            1. -XX:+UseCMSCompactAtFullCollection：使用并发收集器时，开启对年老代的压缩。
            2. -XX:CMSFullGCsBeforeCompaction=0：上面配置开启的情况下，这里设置多少次Full GC后，对年老代进行压缩
        
        代码层面：
        1、避免创建过大的对象及数组：过大的对象或数组在新生代没有足够空间容纳时会直接进入老年代，如果是短命的大对象，会提前出发Full GC。
        2、避免同时加载大量数据，如一次从数据库中取出大量数据，或者一次从Excel中读取大量记录，可以分批读取，用完尽快清空引用。
        3、当集合中有对象的引用，这些对象使用完之后要尽快把集合中的引用清空，这些无用对象尽快回收避免进入老年代。
        4、尽量避免长时间等待外部资源（数据库、网络、设备资源等）的情况，缩小对象的生命周期，避免进入老年代，如果不能及时返回结果可以适当采用异步处理的方式等。
            
24、GC用什么收集器，收集过程如何，那些部分可作为GC Root
    GC收集器如下：-https://www.jianshu.com/p/dc8de441961b
        新生代收集器：
            Serial-单线程收集。使用复制算法
            ParNew-是Serial的多线程版本。也采用复制算法，很多都和Serial一样，只不过它STW时采用多线程并发执行回收操作。
            Parallel Scavnge-多线程回收、复制算法。目标是达到一个可控制的吞吐量
        老年代收集器：
            Serial Old-Serial的老生代版本。单线程、标记整理
            Parallel Old-Parallel Scavnge的老年代版本。多线程标记整理。
            cms-高并发、低停顿，追求最短GC回收停顿时间，cpu占用比较高，响应时间快，停顿时间短，多核cpu 追求高响应时间的选择。。标记清除，可以设置参数进行内存整理
                过程：
                初始标记：STW只标记GC Roots直接引用的对象
                并发标记：和用户线程并发执行可达性分析标记
                重新标记：STW修正并发标记中修改的部分
                并发清除：和用户线程并发执行清除工作。
                缺点：
                CPU资源敏感，因为并发标记会占用一定CPU资源，导致用户线程的资源变小。
                无法处理浮动垃圾，因为清理阶段是和用户线程并发的，所以在清除过程中还会产生垃圾。
                内存空间碎片。
        G1回收器-整体是标记整理，局部是复制算法。
            G1管理整个GC堆，分成不同的Region，维护一个优先列表，记录每个Region的价值，价值是由之前这个区域GC所获空间大小和GC所需时间来决定的。
            
            初始标记：STW标记GC Roots直接引用的对象。
            并发标记：和用户线程并发执行可达性分析标记，这个过程中的引用变化会记录到Remebered Set Logs。
            最终标记：STW修正并发标记过程中改变的引用，合并Remebered Set Logs到Rememebered Set。
            筛选回收：对所有Region进行价值排序，根据用户决定的GC耗时来取价值高的Region进行回收工作。这个部分是STW，因为只对部分区域回收，不会太耗时，并且耗时时间也是用户自己决定的。



    
25、dubbo超时重试，dubbo超时时间设置
    消费者：@Reference(timeout=3000, retries=2)-当消费者请求一个服务时出现错误，会重试连接其他的服务器，但重试会带来更多的延迟
    提供者：@Service(retries=5)-由于网络或服务端不可靠，会导致调用出现一种不确定的中间状态（超时）为了避免超时导致客户端资源（线程）挂起耗尽，必须设置超时时间。超时时间可以使用timeout="超时次数"来设置
    1、方法级的配置的优先级>接口级配置的优先级>全局级配置的优先级
    2、在同级情况下，消费者的优先级大于提供者的优先级；
    3、优先级高的会将优先级低的覆盖；
    配置原则：
    dubbo推荐在Provider上尽量多配置Consumer端属性：
        1、作为服务的提供者，比服务方更清楚服务性能的参数，如调用时间，合理的重试次数等，所以这些参数应尽量配置在服务的提供者方；
        2、在provider配置后，Consumer不配置则会使用provider的配置值，即provider的配置会作为consumer配置的缺省值。
            如果使用consumer的全局配置，这对于provider是不可控的，并且是不合理的。
        

26、分布式事务与分布式锁
    分布式锁：-控制分布式系统有序的去对共享资源进行操作，通过互斥来保持一致性。
        具备的条件：
            ①分布式环境下，一个方法在同一时间只能被一个机器的一个线程执行
            ②高可用的获取锁和释放锁
            ③高性能的获取锁和释放锁
            ④具备可重入特性
            ⑤具备锁失效机制，防止死锁
        分布式锁的三种实现：
            A. 基于数据库实现分布式锁；
                在数据库中创建一个表，表中包含方法名等字段，并在方法名字段上创建唯一索引，想要执行某个方法，就是用这个方法名向表中插入数据，成功插入则获取锁，执行完成后删除对应的行数据释放锁
            B. 基于缓存（Redis等）实现分布式锁；
                （1）获取锁的时候，使用setnx加锁，并使用expire 命令为锁添加一个超时时间，超过该时间则自动释放锁，
                    锁的value值为一个随机生成的UUID,通过此在释放锁的时候进行判断。（setnx和expire中间发生了服务down机 那么key将没有超时时间 会一直存在，新的请求永远进不来，采用Lua脚本可以解决）
                （2）获取锁的时候设置一个获取的超时时间，若超过这个时间就放弃获取锁。
                （3）释放锁的时候，通过UUID判断是不是该锁，若是该锁，就执行delete进行锁释放。（需要保证原子性，判断value是否是当前value）
            C. 基于Zookeeper实现分布式锁
                创建一个目录mylock
                线程A想获取锁就在mylock目录下创建临时顺序节点
                获取mylock目录下所有的子节点，然后获取比自己小的兄弟节点，如果不存在，则说明当前线程顺序号最小，获得锁；
                线程B获取所有节点，判断自己是不是最小的节点，设置监听比自己次小的节点
                线程A处理完，删除自己的节点，线程B监听到便跟事件，判断自己是不是最小的节点，如果是则获得锁。
                使用Apache的开源库Curator，它是一个Zookeeper客户端，Curator提供的InterProcessMutex是分布式锁的实现，acquire方法用于获取锁，release方法用于释放锁。
    分布式事务：
        在CAP定理中，一致性、可用性、分区容错性是不可能同时存在的。但在实际的应用场景中，数据的一致性是需要保证的。
        即保证执行结果的正确性；保证数据的一致性；ACID（原子性、一致性、隔离性和持久性）
        常见的事务处理机制：
            Master-Slave 复制：Slave一般是Master的备份。读写都在Master上，异步同步数据到Slave；Master挂了，Slave只能读。
            Master-Master多主复制：2个以上Master，都提供读写服务。一台挂了，另一台正常读写。
        1、强一致性解决方案
            1.1、XA两阶段提交（2PC）（业务无侵入）
                第一阶段：coordinator（协调者）发起一个提议，分别问询各participant（参与者）是否接受。participant执行本地事务, 结果给coordinator。
                第二阶段：coordinator根据participant的反馈，下达提交或中止事务，如果participant全部同意则提交，只要有一个participant不同意就中止。
                注：如果在发送的过程中出现宕机，那么参与者将进入阻塞状态，一直等待协调者回应，这个时候协调者备份接替协调者工作，询问各个参与者状态，决定阶段2是提交还是终止
                    这也要求 coordinator/participant 记录(logging)历史状态，以备coordinator宕机后watchdog对participant查询、coordinator宕机恢复后重新找回状态。
                优点 : 从流程上我们可以看出来,XA保证数据的强一致性,要么一起提交,要么一起回滚
                缺点：数据库必须提供对XA的支持,例如MySQL 5.7以下的版本受协议约束,事务资源(数据库连接)的锁定周期较长,而且因为事务资源的管理器是数据库本身,我们无法在应用层做处理,所以就导致了我们很难优化其性能
                    一旦事务协调者宕机或者发生网络抖动，会让参与者一直处于锁定资源的状态或者只有一部分参与者提交成功，导致数据的不一致。因此，在⾼并发性能⾄上的场景中，基于 XA 协议的分布式事务并不是最佳选择。
            1.2、三阶段提交（3PC）
                为了解决2PC阶段的阻塞问题，2PC 中只有协调者有超时机制，3PC 在协调者和参与者中都引入了超时机制，协调者出现故障后，参与者就不会一直阻塞，相比2PC，3PC增加了一个准备提交(prepare to commit)阶段。
                在2PC中一个participant的状态只有它自己和coordinator知晓，假如coordinator提议后自身宕机，在watchdog启用前一个participant又宕机，其他participant就会进入既不能回滚、又不能强制commit的阻塞状态，直到participant宕机恢复。
                第一阶段：cancommit 是否可以执行事务（宝贝可以提交了吗？）
                第二阶段：precommit 准备提交阶段 执行事务, 不提交, 返回给协调者（亲爱的要不要试着提交一下呢？）
                第三阶段：docommit
                    因为有了准备提交(prepare to commit)阶段，3PC的事务处理延时也增加了1个RTT，变为3个RTT(propose+precommit+commit)，但是它防止participant宕机后整个系统进入阻塞态，增强了系统的可用性，对一些现实业务场景是非常值得的。
                    虽然 3PC 用超时机制，解决了协调者故障后参与者的阻塞问题，但与此同时却多了一次网络通信，性能上反而变得更差，也不太推荐。
            1.3、TCC补偿机制（侵入业务）-https://blog.csdn.net/f1004145107/article/details/86648263
            所谓的 TCC 编程模式，也是两阶段提交的一个变种，不同的是 TCC 为在业务层编写代码实现的两阶段提交
                第一阶段：Try, 试试是否可执行，预留业务资源,对当前系统做校验,检查当前系统是否准备好提交,与XA的preCommit类似
                第二阶段：Confirm, 执行业务, 直接提交, try 成功, confirm 也就成功
                第三阶段：Cancel, 业务出错了, 在回滚, 单独一个方法， 如果try执行失败,则回滚事务,并释放预留资源 
                优点 : 给了开发人员更大的施展空间,方便拓展,与XA一样,在强一致性上保持的不错
                缺点 : 对业务的侵入性很大,每一个分布式的分支都需要实现try,confirm,cancel操作,如果一旦需要改造,那绝对很让人愤怒
        2、最终一致性解决方案
            2.1、本地消息列表
                A执行事务成功, 发送到消息队列
                B从消息队列取出数据, 执行事务
                B 执行成功或失败, 通知 A, 决定提交还是回滚
            2.2、MQ消息队列：RabbitMQ 和 Kafka 不支持事务消息, RocketMQ 支持（最大努力通知）
                A先发送消息到事务队列, 状态为Prepare, 这个消息不会被消费
                A执行本地事务成功了, 发送Confirm, 把队列改成可消费状态
                B拿到消息后, 开始执行事务, 发送ACK, 修改队列的状态
                A看队列的状态决定提交还是回滚
            2.3、Seata-Seata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。
        3、分布式锁
27、如何保证请求执行顺序
    ①首先，一般来说，从业务逻辑上最好设计系统不需要这种顺序的保证，因为一旦引入顺序性保障，会导致系统复杂度的上升，效率会降低，对于热点数据会压力过大等问题。
    ②操作串行化。首先使用一致性hash负载均衡策略，将同一个id的请求都分发到同一个机器上面去处理，比如订单可以根据订单id。如果处理的机器上面是多线程处理的，可以引入内存队列去处理，将相同id的请求通过hash到同一个队列当中，一个队列只对应一个处理线程。
    ③最好能将多个操作合并成一个操作。

28、zookeper有那些作用
    持久节点：节点创建后会一直存在zookeeper服务器上，直到主动删除
    持久顺序节点：每个节点都会为它的一级子节点维护一个顺序
    临时节点：临时节点的生命周期和客户端的会话保持一致。当客户端会话失效，该节点自动清理
    临时顺序节点：在临时节点上多了一个顺序的特性
    作用：
        数据发布/订阅：zookeeper采用推拉结合的方式来实现发布订阅系统：客户端向服务端注册自己需要关注的节点，一旦该节点的数据发生变更，那么服务端就会向相应的客户端发送Watcher事件通知，客户端接收到这个消息通知之后，需要主动到服务端获取最新的数据。
        负载均衡：每台服务端在启动时都会去zookeeper的servers节点下注册临时节点（注册临时节点是因为，当服务不可用时，这个临时节点会消失，客户端也就不会请求这个服务端），每台客户端在启动时都会去servers节点下取得所有可用的工作服务器列表，并通过一定的负载均衡算法计算得出应该将请求发到哪个服务器上
        命名服务：命名服务是分布式系统中比较常见的一类场景。在分布式系统中，被命名的实体通常可以是集群中的机器，提供的服务地址或远程对象等-这些我们都可以统称他们为名字，其中较为常见的就是一些分布式服务框架（如RPC，RMI）中的服务地址列表，通过命名服务，客户端应用能够根据指定名字来获取资源的实体，服务地址和提供者的信息等。分布式环境中，上层应用仅仅需要一个全局唯一的名字，类似于数据库中的唯一主键，我们可以利用zookeeper的持久顺序节点来实现分布式全局唯一ID
        生成分布式唯一ID：每次要生成一个新Id时，创建一个持久顺序节点，创建操作返回的节点序号，即为新Id，然后把比自己节点小的删除即可。
        master选举：Master选举是一个在分布式系统中非常常见的应用场景。在分布式系统中，Master往往用来协调系统中的其他系统单元，具有对分布式系统状态变更的决定权。例如，在一些读写分离的应用场景用，客户端的写请求往往是由Master来处理的，而在另一些场景中， Master则常常负负责处理一下复杂的逻辑，并将处理结果同步给集群中其他系统单元。Master选举可以说是zookeeper最典型的应用场景了利用zookeeper的强一致性，能够狠好地保证在分布式高并发情况下节点的创建一定能保证全局唯一性，即zookeeper将会保证客户端无法重复创建一个已经存在的数据节点。也就是说，如果同时有多个客户端请求创建同一个节点，那么最终一定只有一个客户端能够创建成功。利用这个特性，就很容易在分布式环境中进行Master选举了。
        分布式锁：临时有序节点
        分布式队列：创建/queue作为一个队列，然后每创建一个顺序节点，视为一条消息(节点存储的数据即为消息内容)，生产者每次创建一个新节点，做为消息发送，消费者监听queue的子节点变化（或定时轮询)，每次取最小节点当做消费消息，处理完后，删除该节点。相当于实现了一个FIFO(先进先出)的队列。
29、数据库的垂直和水平拆分
    拆分前：
     第一步：采用分布式缓存redis、memcached等降低对数据库的读操作。
     第二步：如果缓存使用过后，数据库访问量还是非常大，可以考虑数据库读、写分离原则。
     第三步：当我们使用读写分离、缓存后，数据库的压力还是很大的时候，这就需要使用到数据库拆分了。
   
    垂直拆分：-垂直拆分是把不同的表拆到不同的数据库中
        专库专用，一个数据库由很多表的构成，每个表对应着不同的业务，垂直切分是指按照业务将表进行分类，分布到不同的数据库上面，这样也就将数据或者说压力分担到不同的库上面，
        优点：
        1. 拆分后业务清晰，拆分规则明确。
        2. 系统之间整合或扩展容易。
        3. 数据维护简单。
        缺点：
        1. 部分业务表无法join，只能通过接口方式解决，提高了系统复杂度。
        2. 受每种业务不同的限制存在单库性能瓶颈，不易数据扩展跟性能提高。
        3. 事务处理复杂。
    水平拆分：-而水平拆分是把同一个表拆到不同的数据库中
        按照某个字段的某种规则来分散到多个库之中，每个表中包含一部分数据。
        优点：
        1. 不存在单库大数据，高并发的性能瓶颈。
        2. 对应用透明，应用端改造较少。     
        3. 按照合理拆分规则拆分，join操作基本避免跨库。
        4. 提高了系统的稳定性跟负载能力。
        缺点：
        1. 拆分规则难以抽象。
        2. 分片事务一致性难以解决。
        3. 数据多次扩展难度跟维护量极大。
        4. 跨库join性能较差。
    数据库拆分原则：
    1.优先考虑缓存降低对数据库的读操作。
    2.再考虑读写分离，降低数据库写操作。
    3.最后开始数据拆分,切分模式： 首先垂直（纵向）拆分、再次水平拆分。
    4.首先考虑按照业务垂直拆分。
    5.再考虑水平拆分：先分库(设置数据路由规则，把数据分配到不同的库中)
    6.最后再考虑分表，单表拆分到数据1000万以内。
    切分方案：
        范围、枚举、时间、取模、哈希、指定等
        
30、mybatis如何设置分页；如何设置缓存;mysql分页
    pagehelper
    如何设置缓存：
        一级缓存：默认开启，在同一级会话（SqlSession）层面进行缓存的，不能跨会话共享，分布式环境下会存在脏读
        二级缓存：是为了解决一级缓存不能跨会话共享的问题的，范围是namespace 级别的，可以被多个SqlSession 共享（只要是同一个接口里面的相同方法，都可以共享），生命周期和应用同步。如果你的MyBatis使用了二级缓存，并且你的Mapper和select语句也配置使用了二级缓存，那么在执行select查询的时候，MyBatis会先从二级缓存中取输入，其次才是一级缓存，即MyBatis查询数据的顺序是：二级缓存   —> 一级缓存 —> 数据库。
            可用的清除策略有：
                LRU – 最近最少使用：移除最长时间不被使用的对象。
                FIFO – 先进先出：按对象进入缓存的顺序来移除它们。
                SOFT – 软引用：基于垃圾回收器状态和软引用规则移除对象。
                WEAK – 弱引用：更积极地基于垃圾收集器状态和弱引用规则移除对象。
                默认的清除策略是 LRU。
美团面试：
一，JVM相关
1、对象在jvm中是怎么存储的
2、对象头信息里有那些东西
3、jvm内部如何划分？常量池在哪里？
4、写一段小程序使栈溢出，堆溢出

二、GC
1、gc root 如何确定，那些对象可以作为gc root呢
2、gc如何分代的 没代用什么算法回收
3、CMS过程是怎么样的？内部使用什么算法做垃圾回收呢
4、分代垃圾回收过程

三、并发相关
1、java有哪几种锁
2、synchnized内部原理
3、ReentrantLock内部实现
4、HashMap、HashTable、ConcurrentHashMap区别？内部实现？
5、原子类内部如何实现
6、ArrayBlockingQueue和LinkedBlockingQuene内部如何实现

四、数据库相关
1、innoDB索引数据结构，主建和非主建索引如何区别
2、BTree B+Tree区别？为什么使用B+Tree

四、redis相关
1、项目中那些数据是缓存和数据库双写一份的？如何保证数据库双写一致性
2、热点key的大value问题，某个key出现了热点缓存导致缓存集群中的某个机器负载过高的问题？如何发现和解决
3、超大value打满网卡的问题如何规避
4、工作中是否出现过缓存集群事故，说说细节 说说高可用的保障方案
5、平时如何监控缓存集群的qps和容量
6、缓存集群如何扩容呢
7、说一下Redis集群原理和选举机制
8、key寻址算法有哪些
9、redis线程模型 内存模型
10、底层数据结构了解多少
11、单线程有什么优缺点
12、怎么解决缓存击穿问题

五、算法
写程序判断一颗二叉树是不是完全对称二叉树

写程序判断两颗二叉树是不是相同

六、其他
Comparable和Comarable的区别

内存溢出和内存泄露分别是什么

七、开源框架
1、dubbo如何提供服务？有机器宕调是怎么检测出来的？如何找到服务
2、zk如何管理服务和配置的
3、tair和redis有什么区别
4、redis是单例吗
5、mysql的整理架构是怎么样的
6、了解java的nio吗

八、项目管理
1、项目开发流程
2、如何推动和了解整个项目的情况


蚂蚁金服：-https://xiaojin21cen.blog.csdn.net/article/details/84280141
1、自我介绍、工作经历、技术栈
2、项目中你学到了什么技术？（把三个项目具体描述了很久）
3、微服务划分的粒度
4、微服务的高可用如何保证
5、常用的负载均衡，该怎么用
6、网关能够为后端服务带来哪些好处
7、spring bean的生命周期
8、HashSet是不是线程安全的呢 为什么不是线程安全的
9、java中哪些线程安全的map
10、curhashmap是如何做到线程安全的
11、hashtable
12、如何保证线程安全问题
13、synchnized和lock
14、volatile的原子性问题？为什么i++这种不支持原子性？从计算机设计原理来讲不能保证原子性的原因
15、cas操作
16、公平锁和非公平锁
17、java的读写锁
18、读写锁的设计主要解决什么问题
19、Netty的高性能体现在那些方面
    (1) IO线程模型 ：同步非阻塞，用最少的资源做更多的事情。
    (2) 内存零拷贝 ：尽量减少不必要的内存拷贝，实现了更高效率的传输。
    (3) 内存池设计 ：申请的内存可以重用，主要指直接内存。内部实现是用一颗二叉查找树管理内存分配情况。
    (4) 串行化处理读写 ：避免使用锁带来的性能开销。即消息的处理尽可能再同一个线程内完成，期间不进行线程切换，这样就避免了多线程竞争和同步锁。表面上看，串行化设计似乎CPU利用率不高，并发程度不够。但是，通过调整NIO线程池的线程参数，可以同时启动多个串行化的线程并行运行，这种局部无锁化的串行线程设计相比一个队里-多个工作线程模型性能更优。
    (5) 高性能序列化协议 ：支持protobuf等高性能序列化协议。
    (6) 高效并发编程的体现 ：volatile的大量、正确使用；CAS和原子类的广泛使用；线程安全容器的使用；通过读写锁提升并发性能。

Netty基于Selector对象实现I/O多路复用 使用一个线程可以高效地管理多个 Channel 。
新特性：Netty 4.X相比于Netty 3.X,提供了很多新的特性，例如优化的内存管理池、对MQTT协议的支持等。如果用户需要使用这些新特性，最简便的做法就是升级Netty到4.X系列版本。
更优异的性能：Netty 4.X版本相比于3.X老版本，优化了内存池，减少了GC的频率、降低了内存消耗；通过优化Rector线程池模型，用户的开发更加简单，线程调度也更加高效。
    



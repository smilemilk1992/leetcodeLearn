实战：
# redis-https://www.cnblogs.com/2020-zhy-jzoj/p/13164739.html
1、有没有遇到什么坑

    业务端一般认为redis出现问题，就是redis云有问题，人的“正常”思维：看别人错误容易，发现自己难，扯多了, 出现这个有很多原因：
       (1). 网络原因：比如是否存在跨机房、网络割接等等。
       (2). 慢查询，因为redis是单线程，如果有慢查询的话，会阻塞住之后的操作。 
       (3). value值过大？比如value几十兆，当然这种情况比较少，其实也可以看做是慢查询的一种
       (4). aof重写/rdb fork发生？瞬间会堵一下Redis服务器。
2、redis主从同步过程

    1.从服务发送一个sync同步命令给主服务要求全量同步。
    2.主服务接收到从服务的sync同步命令时，会fork一个子进程后台执行bgsave命令（非阻塞）快照保存，生成RDB文件，并将RDB文件发送给从服务。
    3.从服务再将接收到的RDB文件载入自己的redis内存。
    4.待从服务将RDB载入完成后，主服务再将缓冲区所有写命令发送给从服务。
    5.从服务在将主服务所有的写命令载入内存从而实现数据的完整同步。
    6.从服务下次在需要同步数据时只需要发送自己的offset位置（相当于MySQL binlog的位置）即可，只同步新增加的数据，再不需要全量同步。
    主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。redis 策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。

3、redis哨兵机制-https://www.jianshu.com/p/3677afe376ee

    哨兵(Sentinel)主要是为了解决在主从复制架构中出现宕机的情况,是建立在主从模式的基础上面的
    Redis-Sentinel是Redis官方推荐的高可用（HA）方案，当用Reids 做master-slave高可用方案时，假如master宕机了，redis本身（包括它的很多客服端）都没有实现自动的主备切换，而Redis-Sentinel本身也是一个独立运行的进程，它能监控多个master-slave集群，发现master宕机后能自动切换。



4、redis原理，跳表的时间复杂度

    Redis 是一款基于 ANSI C 语言编写的，BSD 许可的，日志型 key-value 存储组件，它的所有数据结构都存在内存中，可以用作缓存、数据库和消息中间件。
    redis是nosql(也是个巨大的map) 单线程，但是可处理1秒10w的并发（数据都在内存中）
    跳表其实是多条链表组成的链表结构，其特点在于查询时能够跳跃式查询。其复杂度取决于链表的跳跃区间的离散程度。


5、redis集群模式

    * 主从模式（主从模式的弊端就是不具备高可用性，当master挂掉以后，Redis将不能再对外提供写入操作）
        * 主数据库可以进行读写操作，当读写操作导致数据变化时会自动将数据同步给从数据库
        * 从数据库一般都是只读的，并且接收主数据库同步过来的数据
        * 一个master可以拥有多个slave，但是一个slave只能对应一个master
        * slave挂了不影响其他slave的读和master的读和写，重新启动后会将数据从master同步过来
        * master挂了以后，不影响slave的读，但redis不再提供写服务，master重启后redis将重新对外提供写服务
        * master挂了以后，不会在slave节点中重新选一个master
        * 可以实现读写分离，数据备份。但是并不是「高可用」的
    
    * Sentinel模式
        * sentinel模式是建立在主从模式的基础上，如果只有一个Redis节点，sentinel就没有任何意义
        * 当master挂了以后，sentinel会在slave中选择一个做为master，并修改它们的配置文件，其他slave的配置文件也会被修改，比如slaveof属性会指向新的master
        * 当master重新启动后，它将不再是master而是做为slave接收新的master的同步数据
        * sentinel因为也是一个进程有挂掉的可能，所以sentinel也会启动多个形成一个sentinel集群
        * 多sentinel配置的时候，sentinel之间也会自动监控
        * 当主从模式配置密码时，sentinel也会同步将配置信息修改到配置文件中，不需要担心
        * 一个sentinel或sentinel集群可以管理多个主从Redis，多个sentinel也可以监控同一个redis
        * sentinel最好不要和Redis部署在同一台机器，不然Redis的服务器挂了以后，sentinel也挂了
        * Redis哨兵模式实现了高可用，读写分离，但是其主节点仍然只有一个，即写入操作都是在主节点中，这也成为了性能的瓶颈。
    * 集群模式
        * Redis 集群没有使用一致性 hash,而是引入了哈希槽的概念，Redis 集群有 16384 个哈希槽，每个 key 通过 CRC16 校验后对 16384 取模来决定放置哪个槽， 集群的每个节点负责一部分 hash 槽。
        * 集群至少需要3主3从
        * 不仅提供了高可用的手段，同时数据是分片保存在各个节点中的，可以支持高并发的写入与读取。当然实现也是其中最复杂的。
        


6、redis雪崩和穿透怎么解决-https://zhuanlan.zhihu.com/p/58331707  https://www.cnblogs.com/liluxiang/p/10320491.html

    血崩：
    1、redis集群大面积故障
    2、缓存失效，但依然大量请求访问缓存服务redis
    3、redis大量失效后，大量请求转向到mysql数据库
    4、mysql的调用量暴增，很快就扛不住了，甚至直接宕机
    5、由于大量的应用服务依赖mysql和redis的服务，这个时候很快会演变成各服务器集群的雪崩，最后网站彻底崩溃。
    
    如何解决：
    1、缓存高可用
    2、缓存降级
    3、Redis备份和快速预热
    4、提前演练
    
    穿透：
    缓存穿透是指查询一个一不存在的数据。例如：从缓存redis没有命中，需要从mysql数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。
    
    解决：
    如果查询数据库也为空，直接设置一个默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库。设置一个过期时间或者当有值的时候将缓存中的值替换掉即可。

    可以给key设置一些格式规则，然后查询之前先过滤掉不符合规则的Key。
    
7、热点缓存问题-https://www.cnblogs.com/xuwc/p/14013060.html

    热key问题，指的就是缓存集群中的某个key在瞬间被数万甚至十万的并发请求打爆。大value问题，指的是某个key对应的value可能有gb级别的大小，导致查询value的时候会引发网络相关的故障问题。这里说一下热key问题。
    所谓热key问题就是，突然有几十万的请求去访问redis上的某个特定key。那么，这样会造成流量过于集中，达到物理网卡上限，从而导致这台redis的服务器宕机。
    那接下来这个key的请求，就会直接怼到你的数据库上，导致你的服务不可用。

    发现热key:
    1、凭借业务经验，进行预估哪些是热key
    2、在客户端进行收集
    3、在Proxy层做收集
    4、用redis自带命令
    
    如何解决：
    1、利用二级缓存
    比如利用ehcache，或者一个HashMap都可以。在你发现热key以后，把热key加载到系统的JVM中。
    针对这种热key请求，会直接从jvm中取，而不会走到redis层。
    假设此时有十万个针对同一个key的请求过来,如果没有本地缓存，这十万个请求就直接怼到同一台redis上了。
    现在假设，你的应用层有50台机器，OK，你也有jvm缓存了。这十万个请求平均分散开来，每个机器有2000个请求，会从JVM中取到value值，然后返回数据。避免了十万个请求怼到同一台redis上的情形。
    2、备份热key
    这个方案也很简单。不要让key走到同一台redis上不就行了。我们把这个key，在多个redis上都存一份不就好了。接下来，有热key请求进来的时候，我们就在有备份的redis上随机选取一台，进行访问取值，返回数据。
    3、监控热key
    4、通知系统做处理

# hashmap
1、HashMap内部怎么实现的

    HashMap的主干是一个Entry数组。Entry是HashMap的基本组成单元，每一个Entry包含一个key-value键值对。
    简单来说，HashMap由数组+链表+红黑树组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的，如果定位到的数组位置不含链表（当前entry的next指向null）,那么对于查找，添加等操作很快，仅需一次寻址即可；如果定位到的数组包含链表，对于添加操作，其时间复杂度为O(n)，首先遍历链表，存在即覆盖，否则新增；对于查找操作来讲，仍需遍历链表，然后通过key对象的equals方法逐一比对查找。所以，性能考虑，HashMap中的链表出现越少，性能才会越好。
    
2、Hashmap扩容做了什么操作，为什么要扩容成两倍

    扩容的时候1.7需要对原数组中的元素进行重新hash定位在新数组的位置，1.8采用更简单的判断逻辑，位置不变或索引+旧容量大小；
    
    HashMap的初始容量是2的n次幂，扩容也是2倍的形式进行扩容，是因为容量是2的n次幂，可以使得添加的元素均匀分布在HashMap中的数组上，减少hash碰撞，避免形成链表的结构，使得查询效率降低！
    
3、HashMap的put操作过程
 思路如下：
 
    1、如果HashMap没有被初始化过，则初始化
    2、对key求Hash值，然后在计算下标
    3、如果没有碰撞则直接放入桶中
    4、如果碰撞了，以链表的方式链接到后面（尾插法）
    5、如果链表长度超过阈值8，就把链表转为红黑树
    6、如果链表长度低于6，就把红黑树转回链表
    7、如果节点已经存在就替换旧值
    8、如果桶满了（16*加载因子0.75）， 就需要resize（扩容两倍后重排-位置不变或索引+旧容量大小）

4、hashmap线程不安全的体现

    1.在jdk1.7中，在多线程环境下，扩容时会造成环形链或数据丢失。
    2.在jdk1.8中，在多线程环境下，会发生数据覆盖的情况。

#多线程
1、线程池拒绝策略

    1、AbortPolicy-直接抛出拒绝异常（继承自RuntimeException），会中断调用者的处理过程，所以除非有明确需求，一般不推荐
    2、CallerRunsPolicy-在调用者线程中（也就是说谁把 r 这个任务甩来的），运行当前被丢弃的任务。只会用调用者所在线程来运行任务，也就是说任务不会进入线程池。如果线程池已经被关闭，则直接丢弃该任务
    3、DiscardOledestPolicy-丢弃队列中最老的，然后再次尝试提交新任务。
    4、DiscardPolicy-默默丢弃无法加载的任务，不抛出异常。
    
2、volatile的原理
    
    volatile可见性：对一个volatile的读，总可以看到对这个变量最终的写；
    volatile原子性：volatile对单个读/写具有原子性（32位Long、Double），但是复合操作除外，例如：i++；
    jvm底层采用“内存屏障”来实现volatile语义。
    volatile的内存语义及实现：
        在JMM中，线程之间的通信采用共享内存来实现的。
    volatile内存语义是：

        当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值立即刷新到主内存中；
        当读一个volatile变量时，JMM会把该线程对应的本地内存设置为无效，直接从主内存中读取共享变量。
    
    volatile的底层实现是通过插入内存屏障，但是对于编译器来说，发现一个最优布置来最小化插入内存屏障的总数几乎是不可能的，所以，JMM采用保守策略。如下：
    
        在每一个volatile写操作前面插入一个StoreStore屏障
        在每一个volatile写操作后面插入一个StoreLoad屏障
        在每一个volatile读操作后面插入一个LoadLoad屏障
        在每一个volatile读操作后面插入一个LoadStore屏障
    StoreStore屏障可以保证在volatile写之前，其前面的所有普通写操作都已经刷新到主内存中；
    StoreLoad屏障的作用是避免volatile写与后面可能有的volatile读/写操作重排序
    LoadLoad屏障用来禁止处理器把上面的volatile读与下面的普通读重排序
    LoadStore屏障用来禁止处理器把上面的volatile读与下面的普通写重排序
    
    java中volatile关键字提供了一个功能，那就是被其修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在每次使用之前都从主内存刷新。因此，可以使用volatile来保证多线程操作时变量的可见性。
    
    在java中，可以使用synchronized和volatile来保证多线程之间操作的有序性。实现方式有所区别：
    
    1、volatile关键字会禁止指令重排；
    2、synchronized关键字保证同一时刻只允许一条线程操作。 synchronized是万能，他可以同时满足三种特性，这其实也是很多人滥用synchronized的原因。
        
    
3、	线程安全的场景和如何保证

    一般来说如果一个类有自己的可变状态，如成员变量，类变量，并且这些会在执行过程中改变它的值，那么就要考虑线程安全。
    
    如何保证：
    不在线程之间共享状态变量
    将状态变量修改成不可变的变量
    在访问状态变量时使用同步 
    加锁
        

#spring-https://zhuanlan.zhihu.com/p/266901018

```text
依旧以上面A、B类使用属性field注入循环依赖的例子为例，对整个流程做文字步骤总结如下：
使用context.getBean(A.class)，旨在获取容器内的单例A(若A不存在，就会走A这个Bean的创建流程)，显然初次获取A是不存在的，因此走A的创建之路~
实例化A（注意此处仅仅是实例化），并将它放进缓存（此时A已经实例化完成，已经可以被引用了）
初始化A：@Autowired依赖注入B（此时需要去容器内获取B）
为了完成依赖注入B，会通过getBean(B)去容器内找B。但此时B在容器内不存在，就走向B的创建之路~
实例化B，并将其放入缓存。（此时B也能够被引用了）
初始化B，@Autowired依赖注入A（此时需要去容器内获取A）
此处重要：初始化B时会调用getBean(A)去容器内找到A，上面我们已经说过了此时候因为A已经实例化完成了并且放进了缓存里，所以这个时候去看缓存里是已经存在A的引用了的，所以getBean(A)能够正常返回
B初始化成功（此时已经注入A成功了，已成功持有A的引用了），return（注意此处return相当于是返回最上面的getBean(B)这句代码，回到了初始化A的流程中~）。
因为B实例已经成功返回了，因此最终A也初始化成功
到此，B持有的已经是初始化完成的A，A持有的也是初始化完成的B，完美~
```
1、springboot 如何解决循环依赖？

    多个实例之间的相互依赖关系构成一个环形，就是循环依赖
    1、重新设计
        重新设计结构，消除循环依赖。
    2、使用注解@Lazy
        一种最简单的消除循环依赖的方式是通过延迟加载。在注入依赖时，先注入代理对象，当首次使用时再创建对象完成注入。
    3、使用Setter/Field注入
        Spring文档建议的一种方式是使用setter注入。当依赖最终被使用时才进行注入

2、循环依赖会出现什么问题？

    1、循环依赖会产生多米诺骨牌效应
        难以为代码编写测试，因为易变导致写的测试也不稳定
        难以重构，因为互相依赖，你改动一个自然会影响其他依赖对象
        难以维护，你根本不敢想象你的改动会造成什么样的后果
    2、循环依赖会导致内存溢出
    
3、spring循环依赖为什么用三级缓存-https://www.cnblogs.com/semi-sub/p/13548479.html

测试证明，二级缓存也是可以解决循环依赖的。为什么 Spring 不选择二级缓存，而要额外多添加一层缓存呢？

如果 Spring 选择二级缓存来解决循环依赖的话，那么就意味着所有 Bean 都需要在实例化完成之后就立马为其创建代理，而 Spring 的设计原则是在 Bean 初始化完成之后才为其创建代理。所以，Spring 选择了三级缓存。但是因为循环依赖的出现，导致了 Spring 不得不提前去创建代理，因为如果不提前创建代理对象，那么注入的就是原始对象，这样就会产生错误。

我们可以知道 Spring 需要三级缓存的目的是为了在没有循环依赖的情况下，延迟代理对象的创建，使 Bean 的创建符合 Spring 的设计原则。

Spring 解决循环依赖的核心就是提前暴露对象，而提前暴露的对象就是放置于第二级缓存中

| 名称	| 描述 |
| singletonObjects |	一级缓存，存放完整的 Bean。
| earlySingletonObjects |	二级缓存，存放提前暴露的Bean，Bean 是不完整的，未完成属性注入和执行 init 方法。|
| singletonFactories | 三级缓存，存放的是 Bean 工厂，主要是生产 Bean，存放到二级缓存中。 |

    Spring 是如何通过上面介绍的三级缓存来解决循环依赖的呢？这里只用 A，B 形成的循环依赖来举例：
    实例化 A，此时 A 还未完成属性填充和初始化方法（@PostConstruct）的执行，A 只是一个半成品。
    为 A 创建一个 Bean 工厂，并放入到 singletonFactories 中。
    发现 A 需要注入 B 对象，但是一级、二级、三级缓存均为发现对象 B。
    实例化 B，此时 B 还未完成属性填充和初始化方法（@PostConstruct）的执行，B 只是一个半成品。
    为 B 创建一个 Bean 工厂，并放入到 singletonFactories 中。
    发现 B 需要注入 A 对象，此时在一级、二级未发现对象 A，但是在三级缓存中发现了对象 A，从三级缓存中得到对象 A，并将对象 A 放入二级缓存中，同时删除三级缓存中的对象 A。（注意，此时的 A 还是一个半成品，并没有完成属性填充和执行初始化方法）
    将对象 A 注入到对象 B 中。
    对象 B 完成属性填充，执行初始化方法，并放入到一级缓存中，同时删除二级缓存中的对象 B。（此时对象 B 已经是一个成品）
    对象 A 得到对象 B，将对象 B 注入到对象 A 中。（对象 A 得到的是一个完整的对象 B）
    对象 A 完成属性填充，执行初始化方法，并放入到一级缓存中，同时删除二级缓存中的对象 A。
    
4、spring的bean是怎么管理的

    在Spring框架中，一旦把一个bean纳入到Spring IoC容器之中，这个bean的生命周期就会交由容器进行管理，一般担当管理者角色的是BeanFactory或ApplicationContext
    bean对象的生命周期
    1.单例对象（singleton时）
    (1)创建：容器创建时，对象创建。（加载完beans配置文件，对象也就创建了）
    (2)生存：只要容器还在，对象也一直存在。
    (3)消亡：容器销毁，对象消亡。
    总结：单例对象，与容器共存亡。
    
    2.多例对象（singleton时）
    (1)创建：当我们使用对象时，spring框架为我们创建。
    (2)生存：对象只要是在使用过程中就一直存在。
    (3)消亡：对象长时间不用，且没有别的对象引用时，由Java回收机制（GC）回收。
    总结：多例对象，与正常new出来的Java对象的生命周期一样。

5、applicationContext和beanFactory的区别

    ApplicationContext是继承了 BeanFactory 接口 所以 ApplicationContext 包含 BeanFactory 的所有功能以及更多功能
    BeanFactory：bean工厂接口；负责创建bean实例；容器里面保存的所有单例bean其实是一个map；Spring最底层的接口
    ApplicationContext：是容器接口；更多负责容器功能的实现；（可以基于BeanFactory创建好的对象之上完成强大的容器）
    容器可以从map中获取这个bean，并且可以进行aop、di等操作
    BeanFactory是最底层的接口，ApplicationContext留给程序员使用的ioc容器接口；ApplicationContext是BeanFactory的子接口
    ----------------------------------------
    BeanFactory 可以理解为含有bean集合的工厂类。BeanFactory 包含了种bean的定义，以便在接收到客户端请求时将对应的bean实例化。
    BeanFactory还能在实例化对象的时生成协作类之间的关系。此举将bean自身与bean客户端的配置中解放出来。BeanFactory还包含了bean生命周期的控制，调用客户端的初始化方法（initialization methods）和销毁方法（destruction methods）。
    从表面上看，ApplicationContext如同BeanFactory 一样具有bean定义、bean关联关系的设置，根据请求分发bean的功能。但ApplicationContext在此基础上还提供了其他的功能。
    1.提供了支持国际化的文本消息
    2.统一的资源文件读取方式
    3.已在监听器中注册的bean的事件


#锁-https://zhuanlan.zhihu.com/p/139021371 https://www.jianshu.com/p/17be890865e7?utm_campaign=maleskine
1、偏向锁、轻量级锁、自旋锁、重量级锁的转化

7、偏向锁/轻量级锁/重量级锁：

    这三种锁的状态是针对Synchronized而引入的，通过对象监控在对象头中的字段来表明状态
    偏向锁：指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价
    轻量级锁：指当锁是偏向锁时，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能
    重量级锁：指当锁是轻量级锁时，另一个线程虽然自旋，但自旋不会一直持续下去，当自旋到一定次数时，还没获取到锁，就会进入阻塞，该锁膨胀为重量级锁，重量级锁会让其他申请的线程进入阻塞，性能降低
    8、自旋锁：
    自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU

2、读写锁的实现原理

    读写锁的特点是：同一时刻允许多个线程对共享资源进行读操作；同一时刻只允许一个线程对共享资源进行写操作；当进行写操作时，同一时刻其他线程的读操作会被阻塞；当进行读操作时，同一时刻所有线程的写操作会被阻塞。对于读锁而言，由于同一时刻可以允许多个线程访问共享资源，进行读操作，因此称它为共享锁；而对于写锁而言，同一时刻只允许一个线程访问共享资源，进行写操作，因此称它为排他锁。
    读写锁不支持锁升级，支持锁降级。锁升级指的是线程获取到了读锁，在没有释放读锁的前提下，又获取写锁。锁降级指的是线程获取到了写锁，在没有释放写锁的情况下，又获取读锁。
     读写锁同时拥有读锁和写锁，且读共享、写及读写互斥， 当读取数据时用读锁，当没有线程获取到写锁或获取写锁是当前线程时能获取到读锁，多个线程可同时获取到读锁；当写数据时用写锁，当没有线程获取到读锁时，可以获取到写锁，最多只有一个线程能获取到写锁，若当前线程获取到读锁必须要先释放才能获取到写锁。
     
     基于AQS（抽象队列同步器，有一个voliate int state变量和互斥/共享获取、释放锁方法），Java 读写锁用state的高16位表示读锁的线程数，低16位表示写锁的重入数。其中读锁类中的Sync实现共享获取、释放锁方法，写锁类中Sync实现互斥获取、释放锁方法。
     
3、Aqs原理

4、CAS原理

#mysql数据库
1、数据库索引为什么用B+树
    数据库使用B+树肯定是为了提升查找效率。
    答1：B树在提高了IO性能的同时并没有解决元素遍历的我效率低下的问题，正是为了解决这个问题，B+树应用而生。B+树只需要去遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作或者说效率太低。
    答2：1、B+树的磁盘读写代价更低 B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对IO读写次数就降低了。
         2、B+树的查询效率更加稳定 由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。
         3、由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在区间查询的情况，所以通常B+树用于数据库索引。

2、分库分表场景-https://www.cnblogs.com/xdyixia/p/9429475.html https://zhuanlan.zhihu.com/p/144433597 https://zhuanlan.zhihu.com/p/137706956 https://blog.csdn.net/kefengwang/article/details/81213050 https://segmentfault.com/a/1190000020255513 https://www.jianshu.com/p/3dbdd12a7ed7
    分表：-横分纵分
    对于访问极为频繁且数据量巨大的单表（百万到千万级别）来说，我们首先要做的就是减少单表的记录条数，以便减少数据查询所需要的时间，提高数据库的吞吐，这就是所谓的分表！
    
    分库：-横分纵分
    分表能够解决单表数据量过大带来的查询效率下降的问题，但是，却无法给数据库的并发处理能力带来质的提升。
    面对高并发的读写访问，当数据库master服务器无法承载写操作压力时，不管如何扩展slave服务器，此时都没有意义了。
　　 因此，我们必须换一种思路，对数据库进行拆分，从而提高数据库写入能力，这就是所谓的分库!
　　 与分表策略相似，分库可以采用通过一个关键字取模的方式，来对数据访问进行路由

    总的来说，优先考虑分区。当分区不能满足需求时，开始考虑分表，合理的分表对效率的提升会优于分区。
    
    垂直分库-->水平分库-->读写分离 https://www.jianshu.com/p/3dbdd12a7ed7
    
3、慢查询场景
    表索引不合理
    表中存在大尺寸数据字段
    sql语句使用不当-使用LIKE关键字的查询语句

# 消息队列-https://www.cnblogs.com/xiapu5150/p/9927323.html
0、消息中间件如何保证高可用的-https://www.jianshu.com/p/2da7e4b39ceb
        
1、RocketMq的事务消息是怎么实现的
    分为两个逻辑：正常事务消息的发送及提交、事务消息的补偿流程
    事务消息发送及提交：
        发送消息（half消息）
        服务端响应消息写入结果
        根据发送结果执行本地事务（如果写入失败，此时half消息对业务不可见，本地逻辑不执行）
        根据本地事务状态执行Commit或者Rollback（Commit操作生成消息索引，消息对消费者可见）
    补偿流程：
        对没有Commit/Rollback的事务消息（pending状态的消息），从服务端发起一次“回查”
        Producer收到回查消息，检查回查消息对应的本地事务的状态
        根据本地事务状态，重新Commit或者Rollback
        补偿阶段用于解决消息Commit或者Rollback发生超时或者失败的情况。
2、kafka与mq对比-https://www.cnblogs.com/csuliujia/p/9379402.html
    架构方面：
        RabbitMQ遵循AMQP协议，RabbitMQ的broker由Exchange,Binding,queue组成，其中exchange和binding组成了消息的路由键；客户端Producer通过连接channel和server进行通信，Consumer从queue获取消息进行消费（长连接，queue有消息会推送到consumer端，consumer循环从输入流读取数据）。rabbitMQ以broker为中心；有消息的确认机制。
        kafka遵从一般的MQ结构，producer，broker，consumer，以consumer为中心，消息的消费信息保存的客户端consumer上，consumer根据消费的点，从broker上批量pull数据；无消息确认机制。
    吞吐量：
        rabbitMQ在吞吐量方面稍逊于kafka，他们的出发点不一样，rabbitMQ支持对消息的可靠的传递，支持事务，不支持批量的操作；基于存储的可靠性的要求存储可以采用内存或者硬盘。
        kafka具有高的吞吐量，内部采用消息的批量处理，zero-copy机制，数据的存储和获取是本地磁盘顺序批量操作，具有O(1)的复杂度，消息处理的效率很高。
    可用性方面：
        rabbitMQ支持miror的queue，主queue失效，miror queue接管。
        kafka的broker支持主备模式。
    在集群负载均衡方面：
        rabbitMQ的负载均衡需要单独的loadbalancer进行支持。
        kafka采用zookeeper对集群中的broker、consumer进行管理，可以注册topic到zookeeper上；通过zookeeper的协调机制，producer保存对应topic的broker信息，可以随机或者轮询发送到broker上；并且producer可以基于语义指定分片，消息发送到broker的某分片上。
        
3、RabbitMq怎么保证消息的可靠性-https://www.cnblogs.com/linjiqin/p/12683076.html
    (1)开启confirm
    (2)开启RabbitMQ的持久化(交换机、队列、消息)
    (3)关闭RabbitMQ的自动ack(改成手动)
    (4)配置消费重试次数，消费重试间隔时间等
4、Kafka为什么可以保证exactly-Once（即使 producer 重试发送消息）
    1、幂等-partition内部的exactly-once顺序语义 发送到Kafka的每批消息将包含一个序列号，该序列号用于重复数据的删除
    2、事务-跨partition的原子性写操作
5、Kafka怎么保证的高并发高可用
    -kafka
    producer端：
        1、ack=-1 消息发送到leader broker，并且成功写入所有isr的follow 副本才会认为消息发送成功，可靠性最高
        2、控制消息生产速率，防止发送线程跟不上生产线程，buffer打满，导致OOM，比如使用阻塞队列方式来减缓
        3、消息生产时进行持久化到DB或者本地，消息发送成功进行callback删除
    broker端：
        1、通过调节磁盘刷盘机制降低消息丢失概率，同步刷盘/异步刷盘频率提高，减少刷盘量
        2、通过多副本机制来保证
    consumer端：
        1、消费端关闭自动提交改为手动提交，消息成功消费后手动提交offset

# JVM调优-https://www.jianshu.com/p/0e32d7b4c064 https://juejin.cn/post/6896035896916148237
1、CMS和G1回收算法的过程-https://blog.csdn.net/wufaliang003/article/details/80684379

https://img2020.cnblogs.com/other/1218593/202006/1218593-20200617151347151-1115053251.webp

    CMS收集器是基于标记清除算法的一种并发的，低停顿的收集器，值得注意的一点是，CMS只是低停顿而不是没有停顿
    CMS分为以下四步：
    l、初始标记
    2、并发标记
    3、重新标记
    4、并发清除
    标记-清除算法导致的空间碎片 CMS是一款基于“标记-清除”算法实现的收集器，这意味着收集结束时会有大量空间碎片产生。
    空间碎片过多时，将会给大对象分配带来很大麻烦，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象。
    
    G1是一个并行回收器，它把堆内存分割为很多不相关的区间，每个区间可以属于老年代或者年轻代，并且每个年龄代区间可以是物理上不连续的。老年代区间这个设计理念本身是为了服务于并行后台线程，这些线程的主要工作是寻找未被引用的对象，而这样就会产生一种现象，即某些区间的垃圾（未被引用对象）多于其它的区间。垃圾回收时都是需要停下应用程序的，不然就没办法防止应用程序的干扰。G1 GC可以集中精力在垃圾最多的区间上，并且只费一点点时间就可以清空这些区间的垃圾，腾出完全空闲的区间。由于这种方式的侧重点在于处理垃圾最多的区间，所以我们给G1一个名字：垃圾优先（Garbage First）。
    G1内部有四个操作阶段：
    l、初始标记；
    2、并发标记；
    3、最终标记；
    4、筛选回收；
    空间整合 G1从整体来看是基于“标记-整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的。这意味着G1运行期间不会产生内存空间碎片，收集后能提供规整的可用内存。此特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。

2、Outofmemory的场景
    堆内存太小，无法满足应用的需 要
    内存泄漏，泄漏的内存被hold住，无法使用。
    Finalizer线程清理实现了finalize()方法的对象速度慢于生成这些对象的速度。
    数组对象太大， 无法载入堆内存中
    
3、FullGC和OutOfMemory有什么区别，怎么排查
4、Jvm调优的工具和命令-https://zhuanlan.zhihu.com/p/63102801
    关于性能监控这块的工具有linux的top指令及查看进程相关指令，jinfo，jps，jstat，jmap，jstack，jconsole。
    top指令：查看当前所有进程的使用情况，CPU占有率，内存使用情况，服务器负载状态等参数。除此之外它还是个交互命令，使用可参考完全解读top。
    jps：与linux上的ps类似，用于查看有权访问的虚拟机的进程，可以查看本地运行着几个java程序，并显示他们的进程号。当未指定hostid时，默认查看本机jvm进程。
    jinfo：可以输出并修改运行时的java 进程的一些参数。
    jstat：可以用来监视jvm内存内的各种堆和非堆的大小及其内存使用量。
    jstack：堆栈跟踪工具，一般用于查看某个进程包含线程的情况。
    jmap：打印出某个java进程（使用pid）内存内的所有对象的情况。一般用于查看内存占用情况。
    jconsole：一个java GUI监视工具，可以以图表化的形式显示各种数据。并可通过远程连接监视远程的服务器的jvm进程。
    
5、JVM调优经验-结合gc日志、内存监控、使用的垃圾收集器
    1、-Xms -Xmx设置为同样大小
    2、-XX:PermSize=256m -XX:MaxPermSize 一般为256m（jdk1.7）
    3、-XX:ThreadStackSize=512（防止出现StackOverflowError）
    4、-XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=256m（jdk1.8）
    5、-Xmn 响应时间优先的应用尽可能设大（老年代使用并发收集器） 吞吐量优先的也尽可能设大（新生代）
    6、增大新生代空间来降低MinorGC频率
    7、由于堆内存空间不足或老年代对象太多，会触发 Full GC，频繁的 Full GC 会带来上下文切换，增加系统的性能开销 降低Full GC频率
        减少创建大对象
        增大堆内存的空间
    8、选择合适的GC回收器
        如果要求每次操作的响应时间必须在 500ms 以内。这个时候我们一般会选择响应速度较快的 GC 回收器，
        堆内存比较小的情况下（<6G）选择 CMS（Concurrent Mark Sweep）
        回收器和堆内存比较大的情况下（>8G）G1 回收器.
    9、新生代设置越大，老年代就越小，Full GC频率就越高，但Full GC时间越短；相反新生代设置越小，老年代就越大，Full GC频率就越低，但每次Full GC消耗的时间越大
       -Xms和-Xmx的值设置成相等
       新生代尽量设置大一些，让对象在新生代多存活一段时间，每次Minor GC 都要尽可能多的收集垃圾对象，防止或延迟对象进入老年代的机会，以减少应用程序发生Full GC的频率。
       老年代如果使用CMS收集器，新生代可以不用太大，因为CMS的并行收集速度也很快，收集过程比较耗时的并发标记和并发清除阶段都可以与用户线程并发执行。
       
        
    
6、JVM-双亲委派机制
    双亲委派机制得工作过程：
    1-类加载器收到类加载的请求；
    2-把这个请求委托给父加载器去完成，一直向上委托，直到启动类加载器；
    3-启动器加载器检查能不能加载（使用findClass()方法），能就加载（结束）；否则，抛出异常，通知子加载器进行加载。
    4-重复步骤三；
    
    父类加载器能找到的类，子加载器就没有机会加载
    
    为什么要这么做呢？
    如果没有使用双亲委派模型，由各个类加载器自行加载的话，如果用户自己编写了一个称为java.lang.Object的类，并放在程序的ClassPath中，那系统将会出现多个不同的Object类， Java类型体系中最基础的行为就无法保证。应用程序也将会变得一片混乱。
 
    委托机制的意义
    防止内存中出现多份同样的字节码
    比如两个类A和类B都要加载System类：
    如果不用委托而是自己加载自己的，那么类A就会加载一份System字节码，然后类B又会加载一份System字节码，这样内存中就出现了两份System字节码。
    如果使用委托机制，会递归的向父类查找，也就是首选用Bootstrap尝试加载，如果找不到再向下。这里的System就能在Bootstrap中找到然后加载，如果此时类B也要加载System，也从Bootstrap开始，此时Bootstrap发现已经加载过了System那么直接返回内存中的System即可而不需要重新加载，这样内存中就只有一份System的字节码了。

7、JVM调优工具-
    1、JPS可以查看虚拟机启动的所有进程、执行主类的全名、JVM启动参数，比如当执行了
        jps -l 可看到下面的JPSTest类的pid为31354，加上-v参数还可以看到JVM启动参数。
    2、jstat监视虚拟机信息
        jstat -gc pid 500 10 ：每500毫秒打印一次Java堆状况（各个区的容量、使用容量、gc时间等信息），打印10次
    3、jmap查看堆内存信息 
        jmap -histo <pid>可以打印出当前堆中所有每个类的实例数量和内存占用
    4、利用jconsole、jvisualvm、mat分析内存信息
    5、分析堆转储快照
        “-XX:+HeapDumpOnOutOfMemory” 参数可以在程序发生内存溢出时dump出当前的内存快照
        jmap命令随时dump出当时内存状态的快照信息
8、cms G1
    CMS收集器
        CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器,作用于老年代，这是因为CMS收集器工作时，GC工作线程与用户线程可以并发执行，以此来达到降低收集停顿时间的目的。
        CMS收集器是基于标记清除算法的一种并发的，低停顿的收集器，值得注意的一点是，CMS只是低停顿而不是没有停顿
    cms收集器优点：
        并发收集、低停顿。
    cms收集器缺点：
        CMS收集器对CPU资源非常敏感。
        CMS收集器无法处理浮动垃圾（Floating Garbage）。
        算法是标记清除，会产生磁盘碎片
        新生代配合ParNewGC使用，存在STW问题。 --- 时间不可控，如果heap很大，可能GC时间很大，影响线上服务
    
    G1收集器
        G1重新定义了堆空间，打破了原有的分代模型，将堆划分为一个个区域。这么做的目的是在进行收集时不必在全堆范围内进行，这是它最显著的特点。
        区域划分的好处就是带来了停顿时间可预测的收集模型：用户可以指定收集操作在多长时间内完成。即G1提供了接近实时的收集特性。
        一款面向服务器的垃圾收集器，主要针对配备多颗处理器及大容量内存(大概6G以上)的机器；
        G1从jdk7开始，jdk9被设为默认垃圾收集器；目标就是彻底替换掉CMS
    G1收集器优点：
        并行与并发
        分代收集
        空间整合-与CMS的标记-清除算法不同，G1从整体来看是基于标记-整理算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的。但无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。
        可预测gc停顿时间-这是G1相对于CMS的一个优势，降低停顿时间是G1和CMS共同的关注点。
        可根据用户设置停顿时间，制定回收计划(但是也可能存在超出用户的停顿时间).  --- 最主要的目标
    G1收集器缺点：
        G1 需要记忆集 (具体来说是卡表)来记录新生代和老年代之间的引用关系，
        这种数据结构在 G1 中需要占用大量的内存，可能达到整个堆内存容量的 20% 甚至更多。
        而且 G1 中维护记忆集的成本较高，带来了更高的执行负载，影响效率。
    
    对于打算从CMS或者ParallelOld收集器迁移过来的应用，按照官方 的建议，如果发现符合如下特征，可以考虑更换成G1收集器以追求更佳性能：
        实时数据占用了超过半数的堆空间；
        对象分配率或“晋升”的速度变化明显；
        期望消除耗时较长的GC或停顿（超过0.5——1秒）。
    
    G1和CMS适用场景
        实际用cms的挺多，也有更多经验；
        如果都不熟，先看看g1能否达到你的延迟、吞吐目标；
        还有基础配置，如堆大小，比较大，比如16g以上，建议优先g1；30G以上慎用CMS
        如果gc是stw（执行垃圾回收算法出现全局暂停现象）时间过长，一般也是通过G1来解决
        按照《深入理解Java虚拟机》作者的说法，CMS 在小内存应用上的表现要优于 G1，而大内存应用上 G1 更有优势，大小内存的界限是6GB到8GB。
          
5、服务响应慢怎么排查优化
    1.是不是资源层面的瓶颈？
    2.是不是缓存没添加，如果加了，是不是热点数据导致负载不均衡？
    3.是不是有依赖于第三方接口？
    4.是不是接口涉及业务太多，导致程序跑很久？
    5.是不是sql层面的问题导致的等待时机加长，进而拖慢接口？
    6.网络层面的原因？带宽？DNS解析？
    7.代码确实差？？？
    
    解决：
    1.资源紧张，加机器，干上去，负载均衡搞起来
    2.加缓存可以解决的问题都不是什么大问题，存在热点数据可以将某几个热点单独出来用专门的机器进行处理，不要因为局部影响整体
    3.一方面与第三方沟通接口响应问题，另一方面超时时间注意把控，如果可以非核心业务能异步久异步掉。
    4.把非核心的业务进行异步化操作。记住如果代码层面是非核心业务，但是会影响用户感知，需要慎重决定是否异步。
    5.如果是代码不良导致加锁了，尽量优化索引或sql语句，让锁的级别最小（到行），一般来说到行差不多了。如果是单个sql跑慢了，需要分析是不是索引没加或者sql选的索引错了，索引该加的就加了，该force index也加了。
    6.网路原因，需要联系运营商一起商量下怎么解决，单方面比较难有大的优化。
    7.代码确实差，那也无药可救了。我选择狗带。

# 其他
1、以前工作中难度最高和提升最大的项目
2、mysql复合索引的数据结构
    首先我们创建的idx_t1_bcd(b,c,d)索引，相当于创建了(b)、（b、c）（b、c、d）三个索引，看完下面你就知道为什么相当于创建了三个索引。
    我们看，联合索引是首先使用多列索引的第一列构建的索引树，用上面idx_t1_bcd(b,c,d)的例子就是优先使用b列构建，当b列值相等时再以c列排序，若c列的值也相等则以d列排序
    这就像我们的电话本一样，有名和姓以及电话，名和姓就是联合索引。在姓可以以姓的首字母排序，姓的首字母相同的情况下，再以名的首字母排序。
    我们知道名和姓是很快就能够从姓的首字母索引定位到姓，然后定位到名，进而找到电话号码，因为所有的姓从上到下按照既定的规则（首字母排序）是有序的，而名是在姓的首字母一定的条件下也是按照名的首字母排序的，但是整体来看，所有的名放在一起是无序的，所以如果只知道名查找起来就比较慢，因为无法用已排好的结构快速查找。
    到这里大家是否明白了为啥会有最左前缀匹配原则了吧。
    
3、mysql可重复读的实现原理
    MySQL默认的隔离级别是可重复读，即：事务A在读到一条数据之后，此时事务B对该数据进行了修改并提交，那么事务A再读该数据，读到的还是原来的内容。 那么MySQL可重复读是如何实现的呢？
    使用的的一种叫MVCC的控制方式 ，即Mutil-Version Concurrency Control,多版本并发控制，类似于乐观锁的一种实现方式
    实现方式：
        InnoDB在每行记录后面保存两个隐藏的列来，分别保存了这个行的创建时间和行的删除时间。这里存储的并不是实际的时间值,而是系统版本号，当数据被修改时，版本号加1
        在读取事务开始时，系统会给当前读事务一个版本号，事务会读取版本号<=当前版本号的数据
        此时如果其他写事务修改了这条数据，那么这条数据的版本号就会加1，从而比当前读事务的版本号高，读事务自然而然的就读不到更新后的数据了

4、分布式系统的一致性-https://blog.csdn.net/zheng0518/article/details/51194942
    1、强一致性-不保证可用性
    2、弱一致性-不承偌立即可以读到最新写入值
    3、最终一致性-系统最终会返回上一次更新操作的值
    在工程实践上，为了保障系统的可用性，互联网系统大多将强一致性需求转换成最终一致性的需求，并通过系统执行幂等性的保证，保证数据的最终一致性
    1. 规避分布式事务——业务整合
        优点：解决（规避）了分布式事务。
        缺点：显而易见，把本来规划拆分好的业务，又耦合到了一起，业务职责不清晰，不利于维护。
    2. 经典方案 - eBay 模式
        此方案的核心是将需要分布式处理的任务通过消息日志的方式来异步执行。消息日志可以存储到本地文本、数据库或消息队列，再通过业务规则自动或人工发起重试。人工重试更多的是应用于支付场景，通过对账系统对事后问题的处理。
    3. 将分布式事务转换为多个本地事务，然后依靠重试等方式达到最终一致性。
    
    
5、http请求到Tomcat的整体流程
6、怎么保证分布式系统的稳定性-https://zhuanlan.zhihu.com/p/150377297?from_voters_page=true
    1、服务分级
    2、优雅降级
    3、开关可控
    4、服务监视、统计、报表
    5、应急预案
    6、异常兜底
7、MVCC原理，怎么解决的幻读问题
什么是MCVV：
    多版本并发控制。InnoDB为每行记录添加了一个版本号（系统版本号），每当修改数据时，版本号加一。
    在读取事务开始时，系统会给事务一个当前版本号，事务会读取版本号<=当前版本号的数据，这时就算另一个事务插入一个数据，
    并立马提交，新插入这条数据的版本号会比读取事务的版本号高，因此读取事务读的数据还是不会变。解决了幻读的问题。

8、个人优缺点
9、api接口如何保证幂等性-https://blog.csdn.net/ppwwp/article/details/107735205 https://blog.csdn.net/u011635492/article/details/81058153?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.not_use_machine_learn_pai&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.not_use_machine_learn_pai
    1、全局唯一id-mysql redis
    2、去重表-并且把唯一标识作为唯一索引，在我们实现时，把创建支付单据和写入去去重表，放在一个事务中，如果重复创建，数据库会抛出唯一约束异常，操作就会回滚。
    3、多版本控制-这种方法适合在更新的场景中，比如我们要更新商品的名字，这时我们就可以在更新的接口中增加一个版本号，来做幂等 update table_xxx set name=#name#,version=version+1 where id=#id# and version=#version# 
    4、状态机控制-这种方法适合在有状态机流转的情况下，比如就会订单的创建和付款，订单的付款肯定是在之前，这时我们可以通过在设计状态字段时，使用int类型，并且通过值类型的大小来做幂等，比如订单的创建为0，付款成功为100。付款失败为99
        update `order` set status=#{status} where id=#{id} and status<#{status}
# 微服务-https://baijiahao.baidu.com/s?id=1655329799036379323&wfr=spider&for=pc

、ArrayList 与 LinkedList 的不区别？
    
    最明显的区别是 ArrrayList 底层的数据结构是数组，支持随机访问，而 LinkedList 的底层数据结构书链表，不支持随机访问。使用下标访问一个元素， ArrayList 的时间复杂度是 O(1)，而 LinkedList 是 O(n)

Java 中，抽象类与接口之间有什么不同？
    
    Java 中，抽象类和接口有很多不同之处，但是最重要的一个是 Java 中限制一个 类只能继承一个类，但是可以实现多个接口。抽象类可以很好的定义一个家族类 的默认行为，而接口能更好的定义类型，有助于后面实现多态机制。

说出 5 个 JDK 1.8 引入的新特性？
    
       Java 8 在 Java 历史上是一个开创新的版本，下面 JDK 8 中 5 个主要的特性： 
       Lambda 表达式，允许像对象一样传递匿名函数 
       Stream API，充分利用现代多核 CPU，可以写出很简洁的代码 
       Date 与 Time API，最终，有一个稳定、简单的日期和时间库可供你使用 
       扩展方法，现在，接口中可以有静态、默认方法。 
       重复注解，现在你可以将相同的注解在同一类型上使用多次。
